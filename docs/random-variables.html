<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 14 Random variables | Introduction to Data Science</title>
  <meta name="description" content="This book introduces concepts and skills that can help you tackle real-world data analysis challenges. It covers concepts from probability, statistical inference, linear regression and machine learning and helps you develop skills such as R programming, data wrangling with dplyr, data visualization with ggplot2, file organization with UNIX/Linux shell, version control with GitHub, and reproducible document preparation with R markdown." />
  <meta name="generator" content="bookdown 0.12 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 14 Random variables | Introduction to Data Science" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book introduces concepts and skills that can help you tackle real-world data analysis challenges. It covers concepts from probability, statistical inference, linear regression and machine learning and helps you develop skills such as R programming, data wrangling with dplyr, data visualization with ggplot2, file organization with UNIX/Linux shell, version control with GitHub, and reproducible document preparation with R markdown." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 14 Random variables | Introduction to Data Science" />
  
  <meta name="twitter:description" content="This book introduces concepts and skills that can help you tackle real-world data analysis challenges. It covers concepts from probability, statistical inference, linear regression and machine learning and helps you develop skills such as R programming, data wrangling with dplyr, data visualization with ggplot2, file organization with UNIX/Linux shell, version control with GitHub, and reproducible document preparation with R markdown." />
  

<meta name="author" content="Rafael A. Irizarry" />


<meta name="date" content="2019-11-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="probability.html">
<link rel="next" href="inference.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#case-studies"><i class="fa fa-check"></i>Case studies</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#who-will-find-this-book-useful"><i class="fa fa-check"></i>Who will find this book useful?</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#what-does-this-book-cover"><i class="fa fa-check"></i>What does this book cover?</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#what-is-not-covered-by-this-book"><i class="fa fa-check"></i>What is not covered by this book?</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>1</b> Getting started with R and RStudio</a><ul>
<li class="chapter" data-level="1.1" data-path="getting-started.html"><a href="getting-started.html#why-r"><i class="fa fa-check"></i><b>1.1</b> Why R?</a></li>
<li class="chapter" data-level="1.2" data-path="getting-started.html"><a href="getting-started.html#the-r-console"><i class="fa fa-check"></i><b>1.2</b> The R console</a></li>
<li class="chapter" data-level="1.3" data-path="getting-started.html"><a href="getting-started.html#scripts"><i class="fa fa-check"></i><b>1.3</b> Scripts</a></li>
<li class="chapter" data-level="1.4" data-path="getting-started.html"><a href="getting-started.html#rstudio"><i class="fa fa-check"></i><b>1.4</b> RStudio</a><ul>
<li class="chapter" data-level="1.4.1" data-path="getting-started.html"><a href="getting-started.html#the-panes"><i class="fa fa-check"></i><b>1.4.1</b> The panes</a></li>
<li class="chapter" data-level="1.4.2" data-path="getting-started.html"><a href="getting-started.html#key-bindings"><i class="fa fa-check"></i><b>1.4.2</b> Key bindings</a></li>
<li class="chapter" data-level="1.4.3" data-path="getting-started.html"><a href="getting-started.html#running-commands-while-editing-scripts"><i class="fa fa-check"></i><b>1.4.3</b> Running commands while editing scripts</a></li>
<li class="chapter" data-level="1.4.4" data-path="getting-started.html"><a href="getting-started.html#changing-global-options"><i class="fa fa-check"></i><b>1.4.4</b> Changing global options</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="getting-started.html"><a href="getting-started.html#installing-r-packages"><i class="fa fa-check"></i><b>1.5</b> Installing R packages</a></li>
</ul></li>
<li class="part"><span><b>I R</b></span></li>
<li class="chapter" data-level="2" data-path="r-basics.html"><a href="r-basics.html"><i class="fa fa-check"></i><b>2</b> R basics</a><ul>
<li class="chapter" data-level="2.1" data-path="r-basics.html"><a href="r-basics.html#case-study-us-gun-murders"><i class="fa fa-check"></i><b>2.1</b> Case study: US Gun Murders</a></li>
<li class="chapter" data-level="2.2" data-path="r-basics.html"><a href="r-basics.html#the-very-basics"><i class="fa fa-check"></i><b>2.2</b> The very basics</a><ul>
<li class="chapter" data-level="2.2.1" data-path="r-basics.html"><a href="r-basics.html#objects"><i class="fa fa-check"></i><b>2.2.1</b> Objects</a></li>
<li class="chapter" data-level="2.2.2" data-path="r-basics.html"><a href="r-basics.html#the-workspace"><i class="fa fa-check"></i><b>2.2.2</b> The workspace</a></li>
<li class="chapter" data-level="2.2.3" data-path="r-basics.html"><a href="r-basics.html#functions"><i class="fa fa-check"></i><b>2.2.3</b> Functions</a></li>
<li class="chapter" data-level="2.2.4" data-path="r-basics.html"><a href="r-basics.html#other-prebuilt-objects"><i class="fa fa-check"></i><b>2.2.4</b> Other prebuilt objects</a></li>
<li class="chapter" data-level="2.2.5" data-path="r-basics.html"><a href="r-basics.html#variable-names"><i class="fa fa-check"></i><b>2.2.5</b> Variable names</a></li>
<li class="chapter" data-level="2.2.6" data-path="r-basics.html"><a href="r-basics.html#saving-your-workspace"><i class="fa fa-check"></i><b>2.2.6</b> Saving your workspace</a></li>
<li class="chapter" data-level="2.2.7" data-path="r-basics.html"><a href="r-basics.html#motivating-scripts"><i class="fa fa-check"></i><b>2.2.7</b> Motivating scripts</a></li>
<li class="chapter" data-level="2.2.8" data-path="r-basics.html"><a href="r-basics.html#commenting-your-code"><i class="fa fa-check"></i><b>2.2.8</b> Commenting your code</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="r-basics.html"><a href="r-basics.html#exercises"><i class="fa fa-check"></i><b>2.3</b> Exercises</a></li>
<li class="chapter" data-level="2.4" data-path="r-basics.html"><a href="r-basics.html#data-types"><i class="fa fa-check"></i><b>2.4</b> Data types</a><ul>
<li class="chapter" data-level="2.4.1" data-path="r-basics.html"><a href="r-basics.html#data-frames"><i class="fa fa-check"></i><b>2.4.1</b> Data frames</a></li>
<li class="chapter" data-level="2.4.2" data-path="r-basics.html"><a href="r-basics.html#examining-an-object"><i class="fa fa-check"></i><b>2.4.2</b> Examining an object</a></li>
<li class="chapter" data-level="2.4.3" data-path="r-basics.html"><a href="r-basics.html#the-accessor"><i class="fa fa-check"></i><b>2.4.3</b> The accessor: <code>$</code></a></li>
<li class="chapter" data-level="2.4.4" data-path="r-basics.html"><a href="r-basics.html#vectors-numerics-characters-and-logical"><i class="fa fa-check"></i><b>2.4.4</b> Vectors: numerics, characters, and logical</a></li>
<li class="chapter" data-level="2.4.5" data-path="r-basics.html"><a href="r-basics.html#factors"><i class="fa fa-check"></i><b>2.4.5</b> Factors</a></li>
<li class="chapter" data-level="2.4.6" data-path="r-basics.html"><a href="r-basics.html#lists"><i class="fa fa-check"></i><b>2.4.6</b> Lists</a></li>
<li class="chapter" data-level="2.4.7" data-path="r-basics.html"><a href="r-basics.html#matrices"><i class="fa fa-check"></i><b>2.4.7</b> Matrices</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="r-basics.html"><a href="r-basics.html#exercises-1"><i class="fa fa-check"></i><b>2.5</b> Exercises</a></li>
<li class="chapter" data-level="2.6" data-path="r-basics.html"><a href="r-basics.html#vectors"><i class="fa fa-check"></i><b>2.6</b> Vectors</a><ul>
<li class="chapter" data-level="2.6.1" data-path="r-basics.html"><a href="r-basics.html#creating-vectors"><i class="fa fa-check"></i><b>2.6.1</b> Creating vectors</a></li>
<li class="chapter" data-level="2.6.2" data-path="r-basics.html"><a href="r-basics.html#names"><i class="fa fa-check"></i><b>2.6.2</b> Names</a></li>
<li class="chapter" data-level="2.6.3" data-path="r-basics.html"><a href="r-basics.html#sequences"><i class="fa fa-check"></i><b>2.6.3</b> Sequences</a></li>
<li class="chapter" data-level="2.6.4" data-path="r-basics.html"><a href="r-basics.html#subsetting"><i class="fa fa-check"></i><b>2.6.4</b> Subsetting</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="r-basics.html"><a href="r-basics.html#coercion"><i class="fa fa-check"></i><b>2.7</b> Coercion</a><ul>
<li class="chapter" data-level="2.7.1" data-path="r-basics.html"><a href="r-basics.html#not-availables-na"><i class="fa fa-check"></i><b>2.7.1</b> Not availables (NA)</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="r-basics.html"><a href="r-basics.html#exercises-2"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
<li class="chapter" data-level="2.9" data-path="r-basics.html"><a href="r-basics.html#sorting"><i class="fa fa-check"></i><b>2.9</b> Sorting</a><ul>
<li class="chapter" data-level="2.9.1" data-path="r-basics.html"><a href="r-basics.html#sort"><i class="fa fa-check"></i><b>2.9.1</b> <code>sort</code></a></li>
<li class="chapter" data-level="2.9.2" data-path="r-basics.html"><a href="r-basics.html#order"><i class="fa fa-check"></i><b>2.9.2</b> <code>order</code></a></li>
<li class="chapter" data-level="2.9.3" data-path="r-basics.html"><a href="r-basics.html#max-and-which.max"><i class="fa fa-check"></i><b>2.9.3</b> <code>max</code> and <code>which.max</code></a></li>
<li class="chapter" data-level="2.9.4" data-path="r-basics.html"><a href="r-basics.html#rank"><i class="fa fa-check"></i><b>2.9.4</b> <code>rank</code></a></li>
<li class="chapter" data-level="2.9.5" data-path="r-basics.html"><a href="r-basics.html#beware-of-recycling"><i class="fa fa-check"></i><b>2.9.5</b> Beware of recycling</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="r-basics.html"><a href="r-basics.html#exercises-3"><i class="fa fa-check"></i><b>2.10</b> Exercises</a></li>
<li class="chapter" data-level="2.11" data-path="r-basics.html"><a href="r-basics.html#vector-arithmetics"><i class="fa fa-check"></i><b>2.11</b> Vector arithmetics</a><ul>
<li class="chapter" data-level="2.11.1" data-path="r-basics.html"><a href="r-basics.html#rescaling-a-vector"><i class="fa fa-check"></i><b>2.11.1</b> Rescaling a vector</a></li>
<li class="chapter" data-level="2.11.2" data-path="r-basics.html"><a href="r-basics.html#two-vectors"><i class="fa fa-check"></i><b>2.11.2</b> Two vectors</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="r-basics.html"><a href="r-basics.html#exercises-4"><i class="fa fa-check"></i><b>2.12</b> Exercises</a></li>
<li class="chapter" data-level="2.13" data-path="r-basics.html"><a href="r-basics.html#indexing"><i class="fa fa-check"></i><b>2.13</b> Indexing</a><ul>
<li class="chapter" data-level="2.13.1" data-path="r-basics.html"><a href="r-basics.html#subsetting-with-logicals"><i class="fa fa-check"></i><b>2.13.1</b> Subsetting with logicals</a></li>
<li class="chapter" data-level="2.13.2" data-path="r-basics.html"><a href="r-basics.html#logical-operators"><i class="fa fa-check"></i><b>2.13.2</b> Logical operators</a></li>
<li class="chapter" data-level="2.13.3" data-path="r-basics.html"><a href="r-basics.html#which"><i class="fa fa-check"></i><b>2.13.3</b> <code>which</code></a></li>
<li class="chapter" data-level="2.13.4" data-path="r-basics.html"><a href="r-basics.html#match"><i class="fa fa-check"></i><b>2.13.4</b> <code>match</code></a></li>
<li class="chapter" data-level="2.13.5" data-path="r-basics.html"><a href="r-basics.html#in"><i class="fa fa-check"></i><b>2.13.5</b> <code>%in%</code></a></li>
</ul></li>
<li class="chapter" data-level="2.14" data-path="r-basics.html"><a href="r-basics.html#exercises-5"><i class="fa fa-check"></i><b>2.14</b> Exercises</a></li>
<li class="chapter" data-level="2.15" data-path="r-basics.html"><a href="r-basics.html#basic-plots"><i class="fa fa-check"></i><b>2.15</b> Basic plots</a><ul>
<li class="chapter" data-level="2.15.1" data-path="r-basics.html"><a href="r-basics.html#plot"><i class="fa fa-check"></i><b>2.15.1</b> <code>plot</code></a></li>
<li class="chapter" data-level="2.15.2" data-path="r-basics.html"><a href="r-basics.html#hist"><i class="fa fa-check"></i><b>2.15.2</b> <code>hist</code></a></li>
<li class="chapter" data-level="2.15.3" data-path="r-basics.html"><a href="r-basics.html#boxplot"><i class="fa fa-check"></i><b>2.15.3</b> <code>boxplot</code></a></li>
<li class="chapter" data-level="2.15.4" data-path="r-basics.html"><a href="r-basics.html#image"><i class="fa fa-check"></i><b>2.15.4</b> <code>image</code></a></li>
</ul></li>
<li class="chapter" data-level="2.16" data-path="r-basics.html"><a href="r-basics.html#exercises-6"><i class="fa fa-check"></i><b>2.16</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="programming-basics.html"><a href="programming-basics.html"><i class="fa fa-check"></i><b>3</b> Programming basics</a><ul>
<li class="chapter" data-level="3.1" data-path="programming-basics.html"><a href="programming-basics.html#conditionals"><i class="fa fa-check"></i><b>3.1</b> Conditional expressions</a></li>
<li class="chapter" data-level="3.2" data-path="programming-basics.html"><a href="programming-basics.html#defining-functions"><i class="fa fa-check"></i><b>3.2</b> Defining functions</a></li>
<li class="chapter" data-level="3.3" data-path="programming-basics.html"><a href="programming-basics.html#namespaces"><i class="fa fa-check"></i><b>3.3</b> Namespaces</a></li>
<li class="chapter" data-level="3.4" data-path="programming-basics.html"><a href="programming-basics.html#for-loops"><i class="fa fa-check"></i><b>3.4</b> For-loops</a></li>
<li class="chapter" data-level="3.5" data-path="programming-basics.html"><a href="programming-basics.html#vectorization"><i class="fa fa-check"></i><b>3.5</b> Vectorization and functionals</a></li>
<li class="chapter" data-level="3.6" data-path="programming-basics.html"><a href="programming-basics.html#exercises-7"><i class="fa fa-check"></i><b>3.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="tidyverse.html"><a href="tidyverse.html"><i class="fa fa-check"></i><b>4</b> The tidyverse</a><ul>
<li class="chapter" data-level="4.1" data-path="tidyverse.html"><a href="tidyverse.html#tidy-data"><i class="fa fa-check"></i><b>4.1</b> Tidy data</a></li>
<li class="chapter" data-level="4.2" data-path="tidyverse.html"><a href="tidyverse.html#exercises-8"><i class="fa fa-check"></i><b>4.2</b> Exercises</a></li>
<li class="chapter" data-level="4.3" data-path="tidyverse.html"><a href="tidyverse.html#manipulating-data-frames"><i class="fa fa-check"></i><b>4.3</b> Manipulating data frames</a><ul>
<li class="chapter" data-level="4.3.1" data-path="tidyverse.html"><a href="tidyverse.html#adding-a-column-with-mutate"><i class="fa fa-check"></i><b>4.3.1</b> Adding a column with <code>mutate</code></a></li>
<li class="chapter" data-level="4.3.2" data-path="tidyverse.html"><a href="tidyverse.html#subsetting-with-filter"><i class="fa fa-check"></i><b>4.3.2</b> Subsetting with <code>filter</code></a></li>
<li class="chapter" data-level="4.3.3" data-path="tidyverse.html"><a href="tidyverse.html#selecting-columns-with-select"><i class="fa fa-check"></i><b>4.3.3</b> Selecting columns with <code>select</code></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="tidyverse.html"><a href="tidyverse.html#exercises-9"><i class="fa fa-check"></i><b>4.4</b> Exercises</a></li>
<li class="chapter" data-level="4.5" data-path="tidyverse.html"><a href="tidyverse.html#the-pipe"><i class="fa fa-check"></i><b>4.5</b> The pipe: <code>%&gt;%</code></a></li>
<li class="chapter" data-level="4.6" data-path="tidyverse.html"><a href="tidyverse.html#exercises-10"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
<li class="chapter" data-level="4.7" data-path="tidyverse.html"><a href="tidyverse.html#summarizing-data"><i class="fa fa-check"></i><b>4.7</b> Summarizing data</a><ul>
<li class="chapter" data-level="4.7.1" data-path="tidyverse.html"><a href="tidyverse.html#summarize"><i class="fa fa-check"></i><b>4.7.1</b> <code>summarize</code></a></li>
<li class="chapter" data-level="4.7.2" data-path="tidyverse.html"><a href="tidyverse.html#pull"><i class="fa fa-check"></i><b>4.7.2</b> <code>pull</code></a></li>
<li class="chapter" data-level="4.7.3" data-path="tidyverse.html"><a href="tidyverse.html#group-by"><i class="fa fa-check"></i><b>4.7.3</b> Group then summarize with <code>group_by</code></a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="tidyverse.html"><a href="tidyverse.html#sorting-data-frames"><i class="fa fa-check"></i><b>4.8</b> Sorting data frames</a><ul>
<li class="chapter" data-level="4.8.1" data-path="tidyverse.html"><a href="tidyverse.html#nested-sorting"><i class="fa fa-check"></i><b>4.8.1</b> Nested sorting</a></li>
<li class="chapter" data-level="4.8.2" data-path="tidyverse.html"><a href="tidyverse.html#the-top-n"><i class="fa fa-check"></i><b>4.8.2</b> The top <span class="math inline">\(n\)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="tidyverse.html"><a href="tidyverse.html#exercises-11"><i class="fa fa-check"></i><b>4.9</b> Exercises</a></li>
<li class="chapter" data-level="4.10" data-path="tidyverse.html"><a href="tidyverse.html#tibbles"><i class="fa fa-check"></i><b>4.10</b> Tibbles</a><ul>
<li class="chapter" data-level="4.10.1" data-path="tidyverse.html"><a href="tidyverse.html#tibbles-display-better"><i class="fa fa-check"></i><b>4.10.1</b> Tibbles display better</a></li>
<li class="chapter" data-level="4.10.2" data-path="tidyverse.html"><a href="tidyverse.html#subsets-of-tibbles-are-tibbles"><i class="fa fa-check"></i><b>4.10.2</b> Subsets of tibbles are tibbles</a></li>
<li class="chapter" data-level="4.10.3" data-path="tidyverse.html"><a href="tidyverse.html#tibbles-can-have-complex-entries"><i class="fa fa-check"></i><b>4.10.3</b> Tibbles can have complex entries</a></li>
<li class="chapter" data-level="4.10.4" data-path="tidyverse.html"><a href="tidyverse.html#tibbles-can-be-grouped"><i class="fa fa-check"></i><b>4.10.4</b> Tibbles can be grouped</a></li>
<li class="chapter" data-level="4.10.5" data-path="tidyverse.html"><a href="tidyverse.html#create-a-tibble-using-tibble-instead-of-data.frame"><i class="fa fa-check"></i><b>4.10.5</b> Create a tibble using <code>tibble</code> instead of <code>data.frame</code></a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="tidyverse.html"><a href="tidyverse.html#the-dot-operator"><i class="fa fa-check"></i><b>4.11</b> The dot operator</a></li>
<li class="chapter" data-level="4.12" data-path="tidyverse.html"><a href="tidyverse.html#do"><i class="fa fa-check"></i><b>4.12</b> <code>do</code></a></li>
<li class="chapter" data-level="4.13" data-path="tidyverse.html"><a href="tidyverse.html#the-purrr-package"><i class="fa fa-check"></i><b>4.13</b> The <strong>purrr</strong> package</a></li>
<li class="chapter" data-level="4.14" data-path="tidyverse.html"><a href="tidyverse.html#tidyverse-conditionals"><i class="fa fa-check"></i><b>4.14</b> Tidyverse conditionals</a><ul>
<li class="chapter" data-level="4.14.1" data-path="tidyverse.html"><a href="tidyverse.html#case_when"><i class="fa fa-check"></i><b>4.14.1</b> <code>case_when</code></a></li>
<li class="chapter" data-level="4.14.2" data-path="tidyverse.html"><a href="tidyverse.html#between"><i class="fa fa-check"></i><b>4.14.2</b> <code>between</code></a></li>
</ul></li>
<li class="chapter" data-level="4.15" data-path="tidyverse.html"><a href="tidyverse.html#exercises-12"><i class="fa fa-check"></i><b>4.15</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="importing-data.html"><a href="importing-data.html"><i class="fa fa-check"></i><b>5</b> Importing data</a><ul>
<li class="chapter" data-level="5.1" data-path="importing-data.html"><a href="importing-data.html#paths-and-the-working-directory"><i class="fa fa-check"></i><b>5.1</b> Paths and the working directory</a><ul>
<li class="chapter" data-level="5.1.1" data-path="importing-data.html"><a href="importing-data.html#the-filesystem"><i class="fa fa-check"></i><b>5.1.1</b> The filesystem</a></li>
<li class="chapter" data-level="5.1.2" data-path="importing-data.html"><a href="importing-data.html#relative-and-full-paths"><i class="fa fa-check"></i><b>5.1.2</b> Relative and full paths</a></li>
<li class="chapter" data-level="5.1.3" data-path="importing-data.html"><a href="importing-data.html#the-working-directory"><i class="fa fa-check"></i><b>5.1.3</b> The working directory</a></li>
<li class="chapter" data-level="5.1.4" data-path="importing-data.html"><a href="importing-data.html#generating-path-names"><i class="fa fa-check"></i><b>5.1.4</b> Generating path names</a></li>
<li class="chapter" data-level="5.1.5" data-path="importing-data.html"><a href="importing-data.html#copying-files-using-paths"><i class="fa fa-check"></i><b>5.1.5</b> Copying files using paths</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="importing-data.html"><a href="importing-data.html#the-readr-and-readxl-packages"><i class="fa fa-check"></i><b>5.2</b> The readr and readxl packages</a><ul>
<li class="chapter" data-level="5.2.1" data-path="importing-data.html"><a href="importing-data.html#readr"><i class="fa fa-check"></i><b>5.2.1</b> readr</a></li>
<li class="chapter" data-level="5.2.2" data-path="importing-data.html"><a href="importing-data.html#readxl"><i class="fa fa-check"></i><b>5.2.2</b> readxl</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="importing-data.html"><a href="importing-data.html#exercises-13"><i class="fa fa-check"></i><b>5.3</b> Exercises</a></li>
<li class="chapter" data-level="5.4" data-path="importing-data.html"><a href="importing-data.html#downloading-files"><i class="fa fa-check"></i><b>5.4</b> Downloading files</a></li>
<li class="chapter" data-level="5.5" data-path="importing-data.html"><a href="importing-data.html#r-base-importing-functions"><i class="fa fa-check"></i><b>5.5</b> R-base importing functions</a><ul>
<li class="chapter" data-level="5.5.1" data-path="importing-data.html"><a href="importing-data.html#scan"><i class="fa fa-check"></i><b>5.5.1</b> <code>scan</code></a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="importing-data.html"><a href="importing-data.html#text-versus-binary-files"><i class="fa fa-check"></i><b>5.6</b> Text versus binary files</a></li>
<li class="chapter" data-level="5.7" data-path="importing-data.html"><a href="importing-data.html#unicode-versus-ascii"><i class="fa fa-check"></i><b>5.7</b> Unicode versus ASCII</a></li>
<li class="chapter" data-level="5.8" data-path="importing-data.html"><a href="importing-data.html#organizing-data-with-spreadsheets"><i class="fa fa-check"></i><b>5.8</b> Organizing data with spreadsheets</a></li>
<li class="chapter" data-level="5.9" data-path="importing-data.html"><a href="importing-data.html#exercises-14"><i class="fa fa-check"></i><b>5.9</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>II Data Visualization</b></span></li>
<li class="chapter" data-level="6" data-path="introduction-to-data-visualization.html"><a href="introduction-to-data-visualization.html"><i class="fa fa-check"></i><b>6</b> Introduction to data visualization</a></li>
<li class="chapter" data-level="7" data-path="ggplot2.html"><a href="ggplot2.html"><i class="fa fa-check"></i><b>7</b> ggplot2</a><ul>
<li class="chapter" data-level="7.1" data-path="ggplot2.html"><a href="ggplot2.html#the-components-of-a-graph"><i class="fa fa-check"></i><b>7.1</b> The components of a graph</a></li>
<li class="chapter" data-level="7.2" data-path="ggplot2.html"><a href="ggplot2.html#ggplot-objects"><i class="fa fa-check"></i><b>7.2</b> <code>ggplot</code> objects</a></li>
<li class="chapter" data-level="7.3" data-path="ggplot2.html"><a href="ggplot2.html#geometries"><i class="fa fa-check"></i><b>7.3</b> Geometries</a></li>
<li class="chapter" data-level="7.4" data-path="ggplot2.html"><a href="ggplot2.html#aesthetic-mappings"><i class="fa fa-check"></i><b>7.4</b> Aesthetic mappings</a></li>
<li class="chapter" data-level="7.5" data-path="ggplot2.html"><a href="ggplot2.html#layers"><i class="fa fa-check"></i><b>7.5</b> Layers</a><ul>
<li class="chapter" data-level="7.5.1" data-path="ggplot2.html"><a href="ggplot2.html#tinkering-with-arguments"><i class="fa fa-check"></i><b>7.5.1</b> Tinkering with arguments</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="ggplot2.html"><a href="ggplot2.html#global-versus-local-aesthetic-mappings"><i class="fa fa-check"></i><b>7.6</b> Global versus local aesthetic mappings</a></li>
<li class="chapter" data-level="7.7" data-path="ggplot2.html"><a href="ggplot2.html#scales"><i class="fa fa-check"></i><b>7.7</b> Scales</a></li>
<li class="chapter" data-level="7.8" data-path="ggplot2.html"><a href="ggplot2.html#labels-and-titles"><i class="fa fa-check"></i><b>7.8</b> Labels and titles</a></li>
<li class="chapter" data-level="7.9" data-path="ggplot2.html"><a href="ggplot2.html#categories-as-colors"><i class="fa fa-check"></i><b>7.9</b> Categories as colors</a></li>
<li class="chapter" data-level="7.10" data-path="ggplot2.html"><a href="ggplot2.html#annotation-shapes-and-adjustments"><i class="fa fa-check"></i><b>7.10</b> Annotation, shapes, and adjustments</a></li>
<li class="chapter" data-level="7.11" data-path="ggplot2.html"><a href="ggplot2.html#add-on-packages"><i class="fa fa-check"></i><b>7.11</b> Add-on packages</a></li>
<li class="chapter" data-level="7.12" data-path="ggplot2.html"><a href="ggplot2.html#putting-it-all-together"><i class="fa fa-check"></i><b>7.12</b> Putting it all together</a></li>
<li class="chapter" data-level="7.13" data-path="ggplot2.html"><a href="ggplot2.html#qplot"><i class="fa fa-check"></i><b>7.13</b> Quick plots with <code>qplot</code></a></li>
<li class="chapter" data-level="7.14" data-path="ggplot2.html"><a href="ggplot2.html#grids-of-plots"><i class="fa fa-check"></i><b>7.14</b> Grids of plots</a></li>
<li class="chapter" data-level="7.15" data-path="ggplot2.html"><a href="ggplot2.html#exercises-15"><i class="fa fa-check"></i><b>7.15</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>8</b> Visualizing data distributions</a><ul>
<li class="chapter" data-level="8.1" data-path="distributions.html"><a href="distributions.html#variable-types"><i class="fa fa-check"></i><b>8.1</b> Variable types</a></li>
<li class="chapter" data-level="8.2" data-path="distributions.html"><a href="distributions.html#case-study-describing-student-heights"><i class="fa fa-check"></i><b>8.2</b> Case study: describing student heights</a></li>
<li class="chapter" data-level="8.3" data-path="distributions.html"><a href="distributions.html#distribution-function"><i class="fa fa-check"></i><b>8.3</b> Distribution function</a></li>
<li class="chapter" data-level="8.4" data-path="distributions.html"><a href="distributions.html#cdf-intro"><i class="fa fa-check"></i><b>8.4</b> Cumulative distribution functions</a></li>
<li class="chapter" data-level="8.5" data-path="distributions.html"><a href="distributions.html#histograms"><i class="fa fa-check"></i><b>8.5</b> Histograms</a></li>
<li class="chapter" data-level="8.6" data-path="distributions.html"><a href="distributions.html#smoothed-density"><i class="fa fa-check"></i><b>8.6</b> Smoothed density</a><ul>
<li class="chapter" data-level="8.6.1" data-path="distributions.html"><a href="distributions.html#interpreting-the-y-axis"><i class="fa fa-check"></i><b>8.6.1</b> Interpreting the y-axis</a></li>
<li class="chapter" data-level="8.6.2" data-path="distributions.html"><a href="distributions.html#densities-permit-stratification"><i class="fa fa-check"></i><b>8.6.2</b> Densities permit stratification</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="distributions.html"><a href="distributions.html#exercises-16"><i class="fa fa-check"></i><b>8.7</b> Exercises</a></li>
<li class="chapter" data-level="8.8" data-path="distributions.html"><a href="distributions.html#normal-distribution"><i class="fa fa-check"></i><b>8.8</b> The normal distribution</a></li>
<li class="chapter" data-level="8.9" data-path="distributions.html"><a href="distributions.html#standard-units"><i class="fa fa-check"></i><b>8.9</b> Standard units</a></li>
<li class="chapter" data-level="8.10" data-path="distributions.html"><a href="distributions.html#quantile-quantile-plots"><i class="fa fa-check"></i><b>8.10</b> Quantile-quantile plots</a></li>
<li class="chapter" data-level="8.11" data-path="distributions.html"><a href="distributions.html#percentiles"><i class="fa fa-check"></i><b>8.11</b> Percentiles</a></li>
<li class="chapter" data-level="8.12" data-path="distributions.html"><a href="distributions.html#boxplots"><i class="fa fa-check"></i><b>8.12</b> Boxplots</a></li>
<li class="chapter" data-level="8.13" data-path="distributions.html"><a href="distributions.html#stratification"><i class="fa fa-check"></i><b>8.13</b> Stratification</a></li>
<li class="chapter" data-level="8.14" data-path="distributions.html"><a href="distributions.html#student-height-cont"><i class="fa fa-check"></i><b>8.14</b> Case study: describing student heights (continued)</a></li>
<li class="chapter" data-level="8.15" data-path="distributions.html"><a href="distributions.html#exercises-17"><i class="fa fa-check"></i><b>8.15</b> Exercises</a></li>
<li class="chapter" data-level="8.16" data-path="distributions.html"><a href="distributions.html#other-geometries"><i class="fa fa-check"></i><b>8.16</b> ggplot2 geometries</a><ul>
<li class="chapter" data-level="8.16.1" data-path="distributions.html"><a href="distributions.html#barplots"><i class="fa fa-check"></i><b>8.16.1</b> Barplots</a></li>
<li class="chapter" data-level="8.16.2" data-path="distributions.html"><a href="distributions.html#histograms-1"><i class="fa fa-check"></i><b>8.16.2</b> Histograms</a></li>
<li class="chapter" data-level="8.16.3" data-path="distributions.html"><a href="distributions.html#density-plots"><i class="fa fa-check"></i><b>8.16.3</b> Density plots</a></li>
<li class="chapter" data-level="8.16.4" data-path="distributions.html"><a href="distributions.html#boxplots-1"><i class="fa fa-check"></i><b>8.16.4</b> Boxplots</a></li>
<li class="chapter" data-level="8.16.5" data-path="distributions.html"><a href="distributions.html#qq-plots"><i class="fa fa-check"></i><b>8.16.5</b> QQ-plots</a></li>
<li class="chapter" data-level="8.16.6" data-path="distributions.html"><a href="distributions.html#images"><i class="fa fa-check"></i><b>8.16.6</b> Images</a></li>
<li class="chapter" data-level="8.16.7" data-path="distributions.html"><a href="distributions.html#quick-plots"><i class="fa fa-check"></i><b>8.16.7</b> Quick plots</a></li>
</ul></li>
<li class="chapter" data-level="8.17" data-path="distributions.html"><a href="distributions.html#exercises-18"><i class="fa fa-check"></i><b>8.17</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="gapminder.html"><a href="gapminder.html"><i class="fa fa-check"></i><b>9</b> Data visualization in practice</a><ul>
<li class="chapter" data-level="9.1" data-path="gapminder.html"><a href="gapminder.html#case-study-new-insights-on-poverty"><i class="fa fa-check"></i><b>9.1</b> Case study: new insights on poverty</a><ul>
<li class="chapter" data-level="9.1.1" data-path="gapminder.html"><a href="gapminder.html#hans-roslings-quiz"><i class="fa fa-check"></i><b>9.1.1</b> Hans Rosling’s quiz</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="gapminder.html"><a href="gapminder.html#scatterplots"><i class="fa fa-check"></i><b>9.2</b> Scatterplots</a></li>
<li class="chapter" data-level="9.3" data-path="gapminder.html"><a href="gapminder.html#faceting"><i class="fa fa-check"></i><b>9.3</b> Faceting</a><ul>
<li class="chapter" data-level="9.3.1" data-path="gapminder.html"><a href="gapminder.html#facet_wrap"><i class="fa fa-check"></i><b>9.3.1</b> <code>facet_wrap</code></a></li>
<li class="chapter" data-level="9.3.2" data-path="gapminder.html"><a href="gapminder.html#fixed-scales-for-better-comparisons"><i class="fa fa-check"></i><b>9.3.2</b> Fixed scales for better comparisons</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="gapminder.html"><a href="gapminder.html#time-series-plots"><i class="fa fa-check"></i><b>9.4</b> Time series plots</a><ul>
<li class="chapter" data-level="9.4.1" data-path="gapminder.html"><a href="gapminder.html#labels-instead-of-legends"><i class="fa fa-check"></i><b>9.4.1</b> Labels instead of legends</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="gapminder.html"><a href="gapminder.html#data-transformations"><i class="fa fa-check"></i><b>9.5</b> Data transformations</a><ul>
<li class="chapter" data-level="9.5.1" data-path="gapminder.html"><a href="gapminder.html#log-transformation"><i class="fa fa-check"></i><b>9.5.1</b> Log transformation</a></li>
<li class="chapter" data-level="9.5.2" data-path="gapminder.html"><a href="gapminder.html#which-base"><i class="fa fa-check"></i><b>9.5.2</b> Which base?</a></li>
<li class="chapter" data-level="9.5.3" data-path="gapminder.html"><a href="gapminder.html#transform-the-values-or-the-scale"><i class="fa fa-check"></i><b>9.5.3</b> Transform the values or the scale?</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="gapminder.html"><a href="gapminder.html#visualizing-multimodal-distributions"><i class="fa fa-check"></i><b>9.6</b> Visualizing multimodal distributions</a></li>
<li class="chapter" data-level="9.7" data-path="gapminder.html"><a href="gapminder.html#comparing-multiple-distributions-with-boxplots-and-ridge-plots"><i class="fa fa-check"></i><b>9.7</b> Comparing multiple distributions with boxplots and ridge plots</a><ul>
<li class="chapter" data-level="9.7.1" data-path="gapminder.html"><a href="gapminder.html#boxplots-2"><i class="fa fa-check"></i><b>9.7.1</b> Boxplots</a></li>
<li class="chapter" data-level="9.7.2" data-path="gapminder.html"><a href="gapminder.html#ridge-plots"><i class="fa fa-check"></i><b>9.7.2</b> Ridge plots</a></li>
<li class="chapter" data-level="9.7.3" data-path="gapminder.html"><a href="gapminder.html#example-1970-versus-2010-income-distributions"><i class="fa fa-check"></i><b>9.7.3</b> Example: 1970 versus 2010 income distributions</a></li>
<li class="chapter" data-level="9.7.4" data-path="gapminder.html"><a href="gapminder.html#accessing-computed-variables"><i class="fa fa-check"></i><b>9.7.4</b> Accessing computed variables</a></li>
<li class="chapter" data-level="9.7.5" data-path="gapminder.html"><a href="gapminder.html#weighted-densities"><i class="fa fa-check"></i><b>9.7.5</b> Weighted densities</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="gapminder.html"><a href="gapminder.html#the-ecological-fallacy-and-importance-of-showing-the-data"><i class="fa fa-check"></i><b>9.8</b> The ecological fallacy and importance of showing the data</a><ul>
<li class="chapter" data-level="9.8.1" data-path="gapminder.html"><a href="gapminder.html#logit"><i class="fa fa-check"></i><b>9.8.1</b> Logistic transformation</a></li>
<li class="chapter" data-level="9.8.2" data-path="gapminder.html"><a href="gapminder.html#show-the-data"><i class="fa fa-check"></i><b>9.8.2</b> Show the data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html"><i class="fa fa-check"></i><b>10</b> Data visualization principles</a><ul>
<li class="chapter" data-level="10.1" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#encoding-data-using-visual-cues"><i class="fa fa-check"></i><b>10.1</b> Encoding data using visual cues</a></li>
<li class="chapter" data-level="10.2" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#know-when-to-include-0"><i class="fa fa-check"></i><b>10.2</b> Know when to include 0</a></li>
<li class="chapter" data-level="10.3" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#do-not-distort-quantities"><i class="fa fa-check"></i><b>10.3</b> Do not distort quantities</a></li>
<li class="chapter" data-level="10.4" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#order-categories-by-a-meaningful-value"><i class="fa fa-check"></i><b>10.4</b> Order categories by a meaningful value</a></li>
<li class="chapter" data-level="10.5" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#show-the-data-1"><i class="fa fa-check"></i><b>10.5</b> Show the data</a></li>
<li class="chapter" data-level="10.6" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#ease-comparisons"><i class="fa fa-check"></i><b>10.6</b> Ease comparisons</a><ul>
<li class="chapter" data-level="10.6.1" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#use-common-axes"><i class="fa fa-check"></i><b>10.6.1</b> Use common axes</a></li>
<li class="chapter" data-level="10.6.2" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#align-plots-vertically-to-see-horizontal-changes-and-horizontally-to-see-vertical-changes"><i class="fa fa-check"></i><b>10.6.2</b> Align plots vertically to see horizontal changes and horizontally to see vertical changes</a></li>
<li class="chapter" data-level="10.6.3" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#consider-transformations"><i class="fa fa-check"></i><b>10.6.3</b> Consider transformations</a></li>
<li class="chapter" data-level="10.6.4" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#visual-cues-to-be-compared-should-be-adjacent"><i class="fa fa-check"></i><b>10.6.4</b> Visual cues to be compared should be adjacent</a></li>
<li class="chapter" data-level="10.6.5" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#use-color"><i class="fa fa-check"></i><b>10.6.5</b> Use color</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#think-of-the-color-blind"><i class="fa fa-check"></i><b>10.7</b> Think of the color blind</a></li>
<li class="chapter" data-level="10.8" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#plots-for-two-variables"><i class="fa fa-check"></i><b>10.8</b> Plots for two variables</a><ul>
<li class="chapter" data-level="10.8.1" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#slope-charts"><i class="fa fa-check"></i><b>10.8.1</b> Slope charts</a></li>
<li class="chapter" data-level="10.8.2" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#bland-altman-plot"><i class="fa fa-check"></i><b>10.8.2</b> Bland-Altman plot</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#encoding-a-third-variable"><i class="fa fa-check"></i><b>10.9</b> Encoding a third variable</a></li>
<li class="chapter" data-level="10.10" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#avoid-pseudo-three-dimensional-plots"><i class="fa fa-check"></i><b>10.10</b> Avoid pseudo-three-dimensional plots</a></li>
<li class="chapter" data-level="10.11" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#avoid-too-many-significant-digits"><i class="fa fa-check"></i><b>10.11</b> Avoid too many significant digits</a></li>
<li class="chapter" data-level="10.12" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#know-your-audience"><i class="fa fa-check"></i><b>10.12</b> Know your audience</a></li>
<li class="chapter" data-level="10.13" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#exercises-19"><i class="fa fa-check"></i><b>10.13</b> Exercises</a></li>
<li class="chapter" data-level="10.14" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#vaccines"><i class="fa fa-check"></i><b>10.14</b> Case study: vaccines and infectious diseases</a></li>
<li class="chapter" data-level="10.15" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#exercises-20"><i class="fa fa-check"></i><b>10.15</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="robust-summaries.html"><a href="robust-summaries.html"><i class="fa fa-check"></i><b>11</b> Robust summaries</a><ul>
<li class="chapter" data-level="11.1" data-path="robust-summaries.html"><a href="robust-summaries.html#outliers"><i class="fa fa-check"></i><b>11.1</b> Outliers</a></li>
<li class="chapter" data-level="11.2" data-path="robust-summaries.html"><a href="robust-summaries.html#median"><i class="fa fa-check"></i><b>11.2</b> Median</a></li>
<li class="chapter" data-level="11.3" data-path="robust-summaries.html"><a href="robust-summaries.html#the-inter-quartile-range-iqr"><i class="fa fa-check"></i><b>11.3</b> The inter quartile range (IQR)</a></li>
<li class="chapter" data-level="11.4" data-path="robust-summaries.html"><a href="robust-summaries.html#tukeys-definition-of-an-outlier"><i class="fa fa-check"></i><b>11.4</b> Tukey’s definition of an outlier</a></li>
<li class="chapter" data-level="11.5" data-path="robust-summaries.html"><a href="robust-summaries.html#median-absolute-deviation"><i class="fa fa-check"></i><b>11.5</b> Median absolute deviation</a></li>
<li class="chapter" data-level="11.6" data-path="robust-summaries.html"><a href="robust-summaries.html#exercises-21"><i class="fa fa-check"></i><b>11.6</b> Exercises</a></li>
<li class="chapter" data-level="11.7" data-path="robust-summaries.html"><a href="robust-summaries.html#case-study-self-reported-student-heights"><i class="fa fa-check"></i><b>11.7</b> Case study: self-reported student heights</a></li>
</ul></li>
<li class="part"><span><b>III Statistics with R</b></span></li>
<li class="chapter" data-level="12" data-path="introduction-to-statistics-with-r.html"><a href="introduction-to-statistics-with-r.html"><i class="fa fa-check"></i><b>12</b> Introduction to statistics with R</a></li>
<li class="chapter" data-level="13" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>13</b> Probability</a><ul>
<li class="chapter" data-level="13.1" data-path="probability.html"><a href="probability.html#discrete-probability"><i class="fa fa-check"></i><b>13.1</b> Discrete probability</a><ul>
<li class="chapter" data-level="13.1.1" data-path="probability.html"><a href="probability.html#relative-frequency"><i class="fa fa-check"></i><b>13.1.1</b> Relative frequency</a></li>
<li class="chapter" data-level="13.1.2" data-path="probability.html"><a href="probability.html#notation"><i class="fa fa-check"></i><b>13.1.2</b> Notation</a></li>
<li class="chapter" data-level="13.1.3" data-path="probability.html"><a href="probability.html#probability-distributions"><i class="fa fa-check"></i><b>13.1.3</b> Probability distributions</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="probability.html"><a href="probability.html#monte-carlo-simulations-for-categorical-data"><i class="fa fa-check"></i><b>13.2</b> Monte Carlo simulations for categorical data</a><ul>
<li class="chapter" data-level="13.2.1" data-path="probability.html"><a href="probability.html#setting-the-random-seed"><i class="fa fa-check"></i><b>13.2.1</b> Setting the random seed</a></li>
<li class="chapter" data-level="13.2.2" data-path="probability.html"><a href="probability.html#with-and-without-replacement"><i class="fa fa-check"></i><b>13.2.2</b> With and without replacement</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="probability.html"><a href="probability.html#independence"><i class="fa fa-check"></i><b>13.3</b> Independence</a></li>
<li class="chapter" data-level="13.4" data-path="probability.html"><a href="probability.html#conditional-probabilities"><i class="fa fa-check"></i><b>13.4</b> Conditional probabilities</a></li>
<li class="chapter" data-level="13.5" data-path="probability.html"><a href="probability.html#addition-and-multiplication-rules"><i class="fa fa-check"></i><b>13.5</b> Addition and multiplication rules</a><ul>
<li class="chapter" data-level="13.5.1" data-path="probability.html"><a href="probability.html#multiplication-rule"><i class="fa fa-check"></i><b>13.5.1</b> Multiplication rule</a></li>
<li class="chapter" data-level="13.5.2" data-path="probability.html"><a href="probability.html#multiplication-rule-under-independence"><i class="fa fa-check"></i><b>13.5.2</b> Multiplication rule under independence</a></li>
<li class="chapter" data-level="13.5.3" data-path="probability.html"><a href="probability.html#addition-rule"><i class="fa fa-check"></i><b>13.5.3</b> Addition rule</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="probability.html"><a href="probability.html#combinations-and-permutations"><i class="fa fa-check"></i><b>13.6</b> Combinations and permutations</a><ul>
<li class="chapter" data-level="13.6.1" data-path="probability.html"><a href="probability.html#monte-carlo-example"><i class="fa fa-check"></i><b>13.6.1</b> Monte Carlo example</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="probability.html"><a href="probability.html#examples"><i class="fa fa-check"></i><b>13.7</b> Examples</a><ul>
<li class="chapter" data-level="13.7.1" data-path="probability.html"><a href="probability.html#monty-hall-problem"><i class="fa fa-check"></i><b>13.7.1</b> Monty Hall problem</a></li>
<li class="chapter" data-level="13.7.2" data-path="probability.html"><a href="probability.html#birthday-problem"><i class="fa fa-check"></i><b>13.7.2</b> Birthday problem</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="probability.html"><a href="probability.html#infinity-in-practice"><i class="fa fa-check"></i><b>13.8</b> Infinity in practice</a></li>
<li class="chapter" data-level="13.9" data-path="probability.html"><a href="probability.html#exercises-22"><i class="fa fa-check"></i><b>13.9</b> Exercises</a></li>
<li class="chapter" data-level="13.10" data-path="probability.html"><a href="probability.html#continuous-probability"><i class="fa fa-check"></i><b>13.10</b> Continuous probability</a></li>
<li class="chapter" data-level="13.11" data-path="probability.html"><a href="probability.html#theoretical-continuous-distributions"><i class="fa fa-check"></i><b>13.11</b> Theoretical continuous distributions</a><ul>
<li class="chapter" data-level="13.11.1" data-path="probability.html"><a href="probability.html#theoretical-distributions-as-approximations"><i class="fa fa-check"></i><b>13.11.1</b> Theoretical distributions as approximations</a></li>
<li class="chapter" data-level="13.11.2" data-path="probability.html"><a href="probability.html#the-probability-density"><i class="fa fa-check"></i><b>13.11.2</b> The probability density</a></li>
</ul></li>
<li class="chapter" data-level="13.12" data-path="probability.html"><a href="probability.html#monte-carlo-simulations-for-continuous-variables"><i class="fa fa-check"></i><b>13.12</b> Monte Carlo simulations for continuous variables</a></li>
<li class="chapter" data-level="13.13" data-path="probability.html"><a href="probability.html#continuous-distributions"><i class="fa fa-check"></i><b>13.13</b> Continuous distributions</a></li>
<li class="chapter" data-level="13.14" data-path="probability.html"><a href="probability.html#exercises-23"><i class="fa fa-check"></i><b>13.14</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="random-variables.html"><a href="random-variables.html"><i class="fa fa-check"></i><b>14</b> Random variables</a><ul>
<li class="chapter" data-level="14.1" data-path="random-variables.html"><a href="random-variables.html#random-variables-1"><i class="fa fa-check"></i><b>14.1</b> Random variables</a></li>
<li class="chapter" data-level="14.2" data-path="random-variables.html"><a href="random-variables.html#sampling-models"><i class="fa fa-check"></i><b>14.2</b> Sampling models</a></li>
<li class="chapter" data-level="14.3" data-path="random-variables.html"><a href="random-variables.html#the-probability-distribution-of-a-random-variable"><i class="fa fa-check"></i><b>14.3</b> The probability distribution of a random variable</a></li>
<li class="chapter" data-level="14.4" data-path="random-variables.html"><a href="random-variables.html#distributions-versus-probability-distributions"><i class="fa fa-check"></i><b>14.4</b> Distributions versus probability distributions</a></li>
<li class="chapter" data-level="14.5" data-path="random-variables.html"><a href="random-variables.html#notation-for-random-variables"><i class="fa fa-check"></i><b>14.5</b> Notation for random variables</a></li>
<li class="chapter" data-level="14.6" data-path="random-variables.html"><a href="random-variables.html#the-expected-value-and-standard-error"><i class="fa fa-check"></i><b>14.6</b> The expected value and standard error</a><ul>
<li class="chapter" data-level="14.6.1" data-path="random-variables.html"><a href="random-variables.html#population-sd-versus-the-sample-sd"><i class="fa fa-check"></i><b>14.6.1</b> Population SD versus the sample SD</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="random-variables.html"><a href="random-variables.html#central-limit-theorem"><i class="fa fa-check"></i><b>14.7</b> Central Limit Theorem</a><ul>
<li class="chapter" data-level="14.7.1" data-path="random-variables.html"><a href="random-variables.html#how-large-is-large-in-the-central-limit-theorem"><i class="fa fa-check"></i><b>14.7.1</b> How large is large in the Central Limit Theorem?</a></li>
</ul></li>
<li class="chapter" data-level="14.8" data-path="random-variables.html"><a href="random-variables.html#statistical-properties-of-averages"><i class="fa fa-check"></i><b>14.8</b> Statistical properties of averages</a></li>
<li class="chapter" data-level="14.9" data-path="random-variables.html"><a href="random-variables.html#law-of-large-numbers"><i class="fa fa-check"></i><b>14.9</b> Law of large numbers</a><ul>
<li class="chapter" data-level="14.9.1" data-path="random-variables.html"><a href="random-variables.html#misinterpreting-law-of-averages"><i class="fa fa-check"></i><b>14.9.1</b> Misinterpreting law of averages</a></li>
</ul></li>
<li class="chapter" data-level="14.10" data-path="random-variables.html"><a href="random-variables.html#exercises-24"><i class="fa fa-check"></i><b>14.10</b> Exercises</a></li>
<li class="chapter" data-level="14.11" data-path="random-variables.html"><a href="random-variables.html#case-study-the-big-short"><i class="fa fa-check"></i><b>14.11</b> Case study: The Big Short</a><ul>
<li class="chapter" data-level="14.11.1" data-path="random-variables.html"><a href="random-variables.html#interest-rates-explained-with-chance-model"><i class="fa fa-check"></i><b>14.11.1</b> Interest rates explained with chance model</a></li>
<li class="chapter" data-level="14.11.2" data-path="random-variables.html"><a href="random-variables.html#the-big-short"><i class="fa fa-check"></i><b>14.11.2</b> The Big Short</a></li>
</ul></li>
<li class="chapter" data-level="14.12" data-path="random-variables.html"><a href="random-variables.html#exercises-25"><i class="fa fa-check"></i><b>14.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>15</b> Statistical inference</a><ul>
<li class="chapter" data-level="15.1" data-path="inference.html"><a href="inference.html#polls"><i class="fa fa-check"></i><b>15.1</b> Polls</a><ul>
<li class="chapter" data-level="15.1.1" data-path="inference.html"><a href="inference.html#the-sampling-model-for-polls"><i class="fa fa-check"></i><b>15.1.1</b> The sampling model for polls</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="inference.html"><a href="inference.html#populations-samples-parameters-and-estimates"><i class="fa fa-check"></i><b>15.2</b> Populations, samples, parameters, and estimates</a><ul>
<li class="chapter" data-level="15.2.1" data-path="inference.html"><a href="inference.html#the-sample-average"><i class="fa fa-check"></i><b>15.2.1</b> The sample average</a></li>
<li class="chapter" data-level="15.2.2" data-path="inference.html"><a href="inference.html#parameters"><i class="fa fa-check"></i><b>15.2.2</b> Parameters</a></li>
<li class="chapter" data-level="15.2.3" data-path="inference.html"><a href="inference.html#polling-versus-forecasting"><i class="fa fa-check"></i><b>15.2.3</b> Polling versus forecasting</a></li>
<li class="chapter" data-level="15.2.4" data-path="inference.html"><a href="inference.html#properties-of-our-estimate-expected-value-and-standard-error"><i class="fa fa-check"></i><b>15.2.4</b> Properties of our estimate: expected value and standard error</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="inference.html"><a href="inference.html#exercises-26"><i class="fa fa-check"></i><b>15.3</b> Exercises</a></li>
<li class="chapter" data-level="15.4" data-path="inference.html"><a href="inference.html#clt"><i class="fa fa-check"></i><b>15.4</b> Central Limit Theorem in practice</a><ul>
<li class="chapter" data-level="15.4.1" data-path="inference.html"><a href="inference.html#a-monte-carlo-simulation"><i class="fa fa-check"></i><b>15.4.1</b> A Monte Carlo simulation</a></li>
<li class="chapter" data-level="15.4.2" data-path="inference.html"><a href="inference.html#the-spread"><i class="fa fa-check"></i><b>15.4.2</b> The spread</a></li>
<li class="chapter" data-level="15.4.3" data-path="inference.html"><a href="inference.html#bias-why-not-run-a-very-large-poll"><i class="fa fa-check"></i><b>15.4.3</b> Bias: why not run a very large poll?</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="inference.html"><a href="inference.html#exercises-27"><i class="fa fa-check"></i><b>15.5</b> Exercises</a></li>
<li class="chapter" data-level="15.6" data-path="inference.html"><a href="inference.html#confidence-intervals"><i class="fa fa-check"></i><b>15.6</b> Confidence intervals</a><ul>
<li class="chapter" data-level="15.6.1" data-path="inference.html"><a href="inference.html#a-monte-carlo-simulation-1"><i class="fa fa-check"></i><b>15.6.1</b> A Monte Carlo simulation</a></li>
<li class="chapter" data-level="15.6.2" data-path="inference.html"><a href="inference.html#the-correct-language"><i class="fa fa-check"></i><b>15.6.2</b> The correct language</a></li>
</ul></li>
<li class="chapter" data-level="15.7" data-path="inference.html"><a href="inference.html#exercises-28"><i class="fa fa-check"></i><b>15.7</b> Exercises</a></li>
<li class="chapter" data-level="15.8" data-path="inference.html"><a href="inference.html#power"><i class="fa fa-check"></i><b>15.8</b> Power</a></li>
<li class="chapter" data-level="15.9" data-path="inference.html"><a href="inference.html#p-values"><i class="fa fa-check"></i><b>15.9</b> p-values</a></li>
<li class="chapter" data-level="15.10" data-path="inference.html"><a href="inference.html#association-tests"><i class="fa fa-check"></i><b>15.10</b> Association tests</a><ul>
<li class="chapter" data-level="15.10.1" data-path="inference.html"><a href="inference.html#lady-tasting-tea"><i class="fa fa-check"></i><b>15.10.1</b> Lady Tasting Tea</a></li>
<li class="chapter" data-level="15.10.2" data-path="inference.html"><a href="inference.html#two-by-two-tables"><i class="fa fa-check"></i><b>15.10.2</b> Two-by-two tables</a></li>
<li class="chapter" data-level="15.10.3" data-path="inference.html"><a href="inference.html#chi-square-test"><i class="fa fa-check"></i><b>15.10.3</b> Chi-square Test</a></li>
<li class="chapter" data-level="15.10.4" data-path="inference.html"><a href="inference.html#odds-ratio"><i class="fa fa-check"></i><b>15.10.4</b> The odds ratio</a></li>
<li class="chapter" data-level="15.10.5" data-path="inference.html"><a href="inference.html#confidence-intervals-for-the-odds-ratio"><i class="fa fa-check"></i><b>15.10.5</b> Confidence intervals for the odds ratio</a></li>
<li class="chapter" data-level="15.10.6" data-path="inference.html"><a href="inference.html#small-count-correction"><i class="fa fa-check"></i><b>15.10.6</b> Small count correction</a></li>
<li class="chapter" data-level="15.10.7" data-path="inference.html"><a href="inference.html#large-samples-small-p-values"><i class="fa fa-check"></i><b>15.10.7</b> Large samples, small p-values</a></li>
</ul></li>
<li class="chapter" data-level="15.11" data-path="inference.html"><a href="inference.html#exercises-29"><i class="fa fa-check"></i><b>15.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>16</b> Statistical models</a><ul>
<li class="chapter" data-level="16.1" data-path="models.html"><a href="models.html#poll-aggregators"><i class="fa fa-check"></i><b>16.1</b> Poll aggregators</a><ul>
<li class="chapter" data-level="16.1.1" data-path="models.html"><a href="models.html#poll-data"><i class="fa fa-check"></i><b>16.1.1</b> Poll data</a></li>
<li class="chapter" data-level="16.1.2" data-path="models.html"><a href="models.html#pollster-bias"><i class="fa fa-check"></i><b>16.1.2</b> Pollster bias</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="models.html"><a href="models.html#data-driven-model"><i class="fa fa-check"></i><b>16.2</b> Data-driven models</a></li>
<li class="chapter" data-level="16.3" data-path="models.html"><a href="models.html#exercises-30"><i class="fa fa-check"></i><b>16.3</b> Exercises</a></li>
<li class="chapter" data-level="16.4" data-path="models.html"><a href="models.html#bayesian-statistics"><i class="fa fa-check"></i><b>16.4</b> Bayesian statistics</a><ul>
<li class="chapter" data-level="16.4.1" data-path="models.html"><a href="models.html#bayes-theorem"><i class="fa fa-check"></i><b>16.4.1</b> Bayes theorem</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="models.html"><a href="models.html#bayes-theorem-simulation"><i class="fa fa-check"></i><b>16.5</b> Bayes theorem simulation</a><ul>
<li class="chapter" data-level="16.5.1" data-path="models.html"><a href="models.html#bayes-in-practice"><i class="fa fa-check"></i><b>16.5.1</b> Bayes in practice</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="models.html"><a href="models.html#hierarchical-models"><i class="fa fa-check"></i><b>16.6</b> Hierarchical models</a></li>
<li class="chapter" data-level="16.7" data-path="models.html"><a href="models.html#exercises-31"><i class="fa fa-check"></i><b>16.7</b> Exercises</a></li>
<li class="chapter" data-level="16.8" data-path="models.html"><a href="models.html#election-forecasting"><i class="fa fa-check"></i><b>16.8</b> Case study: election forecasting</a><ul>
<li class="chapter" data-level="16.8.1" data-path="models.html"><a href="models.html#bayesian-approach"><i class="fa fa-check"></i><b>16.8.1</b> Bayesian approach</a></li>
<li class="chapter" data-level="16.8.2" data-path="models.html"><a href="models.html#the-general-bias"><i class="fa fa-check"></i><b>16.8.2</b> The general bias</a></li>
<li class="chapter" data-level="16.8.3" data-path="models.html"><a href="models.html#mathematical-representations-of-models"><i class="fa fa-check"></i><b>16.8.3</b> Mathematical representations of models</a></li>
<li class="chapter" data-level="16.8.4" data-path="models.html"><a href="models.html#predicting-the-electoral-college"><i class="fa fa-check"></i><b>16.8.4</b> Predicting the electoral college</a></li>
<li class="chapter" data-level="16.8.5" data-path="models.html"><a href="models.html#forecasting"><i class="fa fa-check"></i><b>16.8.5</b> Forecasting</a></li>
</ul></li>
<li class="chapter" data-level="16.9" data-path="models.html"><a href="models.html#exercises-32"><i class="fa fa-check"></i><b>16.9</b> Exercises</a></li>
<li class="chapter" data-level="16.10" data-path="models.html"><a href="models.html#t-dist"><i class="fa fa-check"></i><b>16.10</b> The t-distribution</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>17</b> Regression</a><ul>
<li class="chapter" data-level="17.1" data-path="regression.html"><a href="regression.html#case-study-is-height-hereditary"><i class="fa fa-check"></i><b>17.1</b> Case study: is height hereditary?</a></li>
<li class="chapter" data-level="17.2" data-path="regression.html"><a href="regression.html#corr-coef"><i class="fa fa-check"></i><b>17.2</b> The correlation coefficient</a><ul>
<li class="chapter" data-level="17.2.1" data-path="regression.html"><a href="regression.html#sample-correlation-is-a-random-variable"><i class="fa fa-check"></i><b>17.2.1</b> Sample correlation is a random variable</a></li>
<li class="chapter" data-level="17.2.2" data-path="regression.html"><a href="regression.html#correlation-is-not-always-a-useful-summary"><i class="fa fa-check"></i><b>17.2.2</b> Correlation is not always a useful summary</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="regression.html"><a href="regression.html#conditional-expectation"><i class="fa fa-check"></i><b>17.3</b> Conditional expectations</a></li>
<li class="chapter" data-level="17.4" data-path="regression.html"><a href="regression.html#the-regression-line"><i class="fa fa-check"></i><b>17.4</b> The regression line</a><ul>
<li class="chapter" data-level="17.4.1" data-path="regression.html"><a href="regression.html#regression-improves-precision"><i class="fa fa-check"></i><b>17.4.1</b> Regression improves precision</a></li>
<li class="chapter" data-level="17.4.2" data-path="regression.html"><a href="regression.html#bivariate-normal-distribution-advanced"><i class="fa fa-check"></i><b>17.4.2</b> Bivariate normal distribution (advanced)</a></li>
<li class="chapter" data-level="17.4.3" data-path="regression.html"><a href="regression.html#variance-explained"><i class="fa fa-check"></i><b>17.4.3</b> Variance explained</a></li>
<li class="chapter" data-level="17.4.4" data-path="regression.html"><a href="regression.html#warning-there-are-two-regression-lines"><i class="fa fa-check"></i><b>17.4.4</b> Warning: there are two regression lines</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="regression.html"><a href="regression.html#exercises-33"><i class="fa fa-check"></i><b>17.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>18</b> Linear models</a><ul>
<li class="chapter" data-level="18.1" data-path="linear-models.html"><a href="linear-models.html#case-study-moneyball"><i class="fa fa-check"></i><b>18.1</b> Case study: Moneyball</a><ul>
<li class="chapter" data-level="18.1.1" data-path="linear-models.html"><a href="linear-models.html#sabermetics"><i class="fa fa-check"></i><b>18.1.1</b> Sabermetics</a></li>
<li class="chapter" data-level="18.1.2" data-path="linear-models.html"><a href="linear-models.html#baseball-basics"><i class="fa fa-check"></i><b>18.1.2</b> Baseball basics</a></li>
<li class="chapter" data-level="18.1.3" data-path="linear-models.html"><a href="linear-models.html#no-awards-for-bb"><i class="fa fa-check"></i><b>18.1.3</b> No awards for BB</a></li>
<li class="chapter" data-level="18.1.4" data-path="linear-models.html"><a href="linear-models.html#base-on-balls-or-stolen-bases"><i class="fa fa-check"></i><b>18.1.4</b> Base on balls or stolen bases?</a></li>
<li class="chapter" data-level="18.1.5" data-path="linear-models.html"><a href="linear-models.html#regression-applied-to-baseball-statistics"><i class="fa fa-check"></i><b>18.1.5</b> Regression applied to baseball statistics</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="linear-models.html"><a href="linear-models.html#confounding"><i class="fa fa-check"></i><b>18.2</b> Confounding</a><ul>
<li class="chapter" data-level="18.2.1" data-path="linear-models.html"><a href="linear-models.html#understanding-confounding-through-stratification"><i class="fa fa-check"></i><b>18.2.1</b> Understanding confounding through stratification</a></li>
<li class="chapter" data-level="18.2.2" data-path="linear-models.html"><a href="linear-models.html#multivariate-regression"><i class="fa fa-check"></i><b>18.2.2</b> Multivariate regression</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="linear-models.html"><a href="linear-models.html#lse"><i class="fa fa-check"></i><b>18.3</b> Least squares estimates</a><ul>
<li class="chapter" data-level="18.3.1" data-path="linear-models.html"><a href="linear-models.html#interpreting-linear-models"><i class="fa fa-check"></i><b>18.3.1</b> Interpreting linear models</a></li>
<li class="chapter" data-level="18.3.2" data-path="linear-models.html"><a href="linear-models.html#least-squares-estimates-lse"><i class="fa fa-check"></i><b>18.3.2</b> Least Squares Estimates (LSE)</a></li>
<li class="chapter" data-level="18.3.3" data-path="linear-models.html"><a href="linear-models.html#the-lm-function"><i class="fa fa-check"></i><b>18.3.3</b> The <code>lm</code> function</a></li>
<li class="chapter" data-level="18.3.4" data-path="linear-models.html"><a href="linear-models.html#lse-are-random-variables"><i class="fa fa-check"></i><b>18.3.4</b> LSE are random variables</a></li>
<li class="chapter" data-level="18.3.5" data-path="linear-models.html"><a href="linear-models.html#predicted-values-are-random-variables"><i class="fa fa-check"></i><b>18.3.5</b> Predicted values are random variables</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="linear-models.html"><a href="linear-models.html#exercises-34"><i class="fa fa-check"></i><b>18.4</b> Exercises</a></li>
<li class="chapter" data-level="18.5" data-path="linear-models.html"><a href="linear-models.html#linear-regression-in-the-tidyverse"><i class="fa fa-check"></i><b>18.5</b> Linear regression in the tidyverse</a><ul>
<li class="chapter" data-level="18.5.1" data-path="linear-models.html"><a href="linear-models.html#the-broom-package"><i class="fa fa-check"></i><b>18.5.1</b> The broom package</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="linear-models.html"><a href="linear-models.html#exercises-35"><i class="fa fa-check"></i><b>18.6</b> Exercises</a></li>
<li class="chapter" data-level="18.7" data-path="linear-models.html"><a href="linear-models.html#case-study-moneyball-continued"><i class="fa fa-check"></i><b>18.7</b> Case study: Moneyball (continued)</a><ul>
<li class="chapter" data-level="18.7.1" data-path="linear-models.html"><a href="linear-models.html#adding-salary-and-position-information"><i class="fa fa-check"></i><b>18.7.1</b> Adding salary and position information</a></li>
<li class="chapter" data-level="18.7.2" data-path="linear-models.html"><a href="linear-models.html#picking-nine-players"><i class="fa fa-check"></i><b>18.7.2</b> Picking nine players</a></li>
</ul></li>
<li class="chapter" data-level="18.8" data-path="linear-models.html"><a href="linear-models.html#the-regression-fallacy"><i class="fa fa-check"></i><b>18.8</b> The regression fallacy</a></li>
<li class="chapter" data-level="18.9" data-path="linear-models.html"><a href="linear-models.html#measurement-error-models"><i class="fa fa-check"></i><b>18.9</b> Measurement error models</a></li>
<li class="chapter" data-level="18.10" data-path="linear-models.html"><a href="linear-models.html#exercises-36"><i class="fa fa-check"></i><b>18.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html"><i class="fa fa-check"></i><b>19</b> Association is not causation</a><ul>
<li class="chapter" data-level="19.1" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#spurious-correlation"><i class="fa fa-check"></i><b>19.1</b> Spurious correlation</a></li>
<li class="chapter" data-level="19.2" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#outliers-1"><i class="fa fa-check"></i><b>19.2</b> Outliers</a></li>
<li class="chapter" data-level="19.3" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#reversing-cause-and-effect"><i class="fa fa-check"></i><b>19.3</b> Reversing cause and effect</a></li>
<li class="chapter" data-level="19.4" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#confounders"><i class="fa fa-check"></i><b>19.4</b> Confounders</a><ul>
<li class="chapter" data-level="19.4.1" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#example-uc-berkeley-admissions"><i class="fa fa-check"></i><b>19.4.1</b> Example: UC Berkeley admissions</a></li>
<li class="chapter" data-level="19.4.2" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#confounding-explained-graphically"><i class="fa fa-check"></i><b>19.4.2</b> Confounding explained graphically</a></li>
<li class="chapter" data-level="19.4.3" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#average-after-stratifying"><i class="fa fa-check"></i><b>19.4.3</b> Average after stratifying</a></li>
</ul></li>
<li class="chapter" data-level="19.5" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#simpsons-paradox"><i class="fa fa-check"></i><b>19.5</b> Simpson’s paradox</a></li>
<li class="chapter" data-level="19.6" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#exercises-37"><i class="fa fa-check"></i><b>19.6</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>IV Data Wrangling</b></span></li>
<li class="chapter" data-level="20" data-path="introduction-to-data-wrangling.html"><a href="introduction-to-data-wrangling.html"><i class="fa fa-check"></i><b>20</b> Introduction to data wrangling</a></li>
<li class="chapter" data-level="21" data-path="reshaping-data.html"><a href="reshaping-data.html"><i class="fa fa-check"></i><b>21</b> Reshaping data</a><ul>
<li class="chapter" data-level="21.1" data-path="reshaping-data.html"><a href="reshaping-data.html#gather"><i class="fa fa-check"></i><b>21.1</b> <code>gather</code></a></li>
<li class="chapter" data-level="21.2" data-path="reshaping-data.html"><a href="reshaping-data.html#spread"><i class="fa fa-check"></i><b>21.2</b> <code>spread</code></a></li>
<li class="chapter" data-level="21.3" data-path="reshaping-data.html"><a href="reshaping-data.html#separate"><i class="fa fa-check"></i><b>21.3</b> <code>separate</code></a></li>
<li class="chapter" data-level="21.4" data-path="reshaping-data.html"><a href="reshaping-data.html#unite"><i class="fa fa-check"></i><b>21.4</b> <code>unite</code></a></li>
<li class="chapter" data-level="21.5" data-path="reshaping-data.html"><a href="reshaping-data.html#exercises-38"><i class="fa fa-check"></i><b>21.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="joining-tables.html"><a href="joining-tables.html"><i class="fa fa-check"></i><b>22</b> Joining tables</a><ul>
<li class="chapter" data-level="22.1" data-path="joining-tables.html"><a href="joining-tables.html#joins"><i class="fa fa-check"></i><b>22.1</b> Joins</a><ul>
<li class="chapter" data-level="22.1.1" data-path="joining-tables.html"><a href="joining-tables.html#left-join"><i class="fa fa-check"></i><b>22.1.1</b> Left join</a></li>
<li class="chapter" data-level="22.1.2" data-path="joining-tables.html"><a href="joining-tables.html#right-join"><i class="fa fa-check"></i><b>22.1.2</b> Right join</a></li>
<li class="chapter" data-level="22.1.3" data-path="joining-tables.html"><a href="joining-tables.html#inner-join"><i class="fa fa-check"></i><b>22.1.3</b> Inner join</a></li>
<li class="chapter" data-level="22.1.4" data-path="joining-tables.html"><a href="joining-tables.html#full-join"><i class="fa fa-check"></i><b>22.1.4</b> Full join</a></li>
<li class="chapter" data-level="22.1.5" data-path="joining-tables.html"><a href="joining-tables.html#semi-join"><i class="fa fa-check"></i><b>22.1.5</b> Semi join</a></li>
<li class="chapter" data-level="22.1.6" data-path="joining-tables.html"><a href="joining-tables.html#anti-join"><i class="fa fa-check"></i><b>22.1.6</b> Anti join</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="joining-tables.html"><a href="joining-tables.html#binding"><i class="fa fa-check"></i><b>22.2</b> Binding</a><ul>
<li class="chapter" data-level="22.2.1" data-path="joining-tables.html"><a href="joining-tables.html#binding-columns"><i class="fa fa-check"></i><b>22.2.1</b> Binding columns</a></li>
<li class="chapter" data-level="22.2.2" data-path="joining-tables.html"><a href="joining-tables.html#binding-by-rows"><i class="fa fa-check"></i><b>22.2.2</b> Binding by rows</a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="joining-tables.html"><a href="joining-tables.html#set-operators"><i class="fa fa-check"></i><b>22.3</b> Set operators</a><ul>
<li class="chapter" data-level="22.3.1" data-path="joining-tables.html"><a href="joining-tables.html#intersect"><i class="fa fa-check"></i><b>22.3.1</b> Intersect</a></li>
<li class="chapter" data-level="22.3.2" data-path="joining-tables.html"><a href="joining-tables.html#union"><i class="fa fa-check"></i><b>22.3.2</b> Union</a></li>
<li class="chapter" data-level="22.3.3" data-path="joining-tables.html"><a href="joining-tables.html#setdiff"><i class="fa fa-check"></i><b>22.3.3</b> <code>setdiff</code></a></li>
<li class="chapter" data-level="22.3.4" data-path="joining-tables.html"><a href="joining-tables.html#setequal"><i class="fa fa-check"></i><b>22.3.4</b> <code>setequal</code></a></li>
</ul></li>
<li class="chapter" data-level="22.4" data-path="joining-tables.html"><a href="joining-tables.html#exercises-39"><i class="fa fa-check"></i><b>22.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="web-scraping.html"><a href="web-scraping.html"><i class="fa fa-check"></i><b>23</b> Web scraping</a><ul>
<li class="chapter" data-level="23.1" data-path="web-scraping.html"><a href="web-scraping.html#html"><i class="fa fa-check"></i><b>23.1</b> HTML</a></li>
<li class="chapter" data-level="23.2" data-path="web-scraping.html"><a href="web-scraping.html#the-rvest-package"><i class="fa fa-check"></i><b>23.2</b> The rvest package</a></li>
<li class="chapter" data-level="23.3" data-path="web-scraping.html"><a href="web-scraping.html#css-selectors"><i class="fa fa-check"></i><b>23.3</b> CSS selectors</a></li>
<li class="chapter" data-level="23.4" data-path="web-scraping.html"><a href="web-scraping.html#json"><i class="fa fa-check"></i><b>23.4</b> JSON</a></li>
<li class="chapter" data-level="23.5" data-path="web-scraping.html"><a href="web-scraping.html#exercises-40"><i class="fa fa-check"></i><b>23.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="string-processing.html"><a href="string-processing.html"><i class="fa fa-check"></i><b>24</b> String processing</a><ul>
<li class="chapter" data-level="24.1" data-path="string-processing.html"><a href="string-processing.html#stringr"><i class="fa fa-check"></i><b>24.1</b> The stringr package</a></li>
<li class="chapter" data-level="24.2" data-path="string-processing.html"><a href="string-processing.html#case-study-1-us-murders-data"><i class="fa fa-check"></i><b>24.2</b> Case study 1: US murders data</a></li>
<li class="chapter" data-level="24.3" data-path="string-processing.html"><a href="string-processing.html#case-study-2-self-reported-heights"><i class="fa fa-check"></i><b>24.3</b> Case study 2: self-reported heights</a></li>
<li class="chapter" data-level="24.4" data-path="string-processing.html"><a href="string-processing.html#how-to-escape-when-defining-strings"><i class="fa fa-check"></i><b>24.4</b> How to <em>escape</em> when defining strings</a></li>
<li class="chapter" data-level="24.5" data-path="string-processing.html"><a href="string-processing.html#regular-expressions"><i class="fa fa-check"></i><b>24.5</b> Regular expressions</a><ul>
<li class="chapter" data-level="24.5.1" data-path="string-processing.html"><a href="string-processing.html#strings-are-a-regexp"><i class="fa fa-check"></i><b>24.5.1</b> Strings are a regexp</a></li>
<li class="chapter" data-level="24.5.2" data-path="string-processing.html"><a href="string-processing.html#special-characters"><i class="fa fa-check"></i><b>24.5.2</b> Special characters</a></li>
<li class="chapter" data-level="24.5.3" data-path="string-processing.html"><a href="string-processing.html#character-classes"><i class="fa fa-check"></i><b>24.5.3</b> Character classes</a></li>
<li class="chapter" data-level="24.5.4" data-path="string-processing.html"><a href="string-processing.html#anchors"><i class="fa fa-check"></i><b>24.5.4</b> Anchors</a></li>
<li class="chapter" data-level="24.5.5" data-path="string-processing.html"><a href="string-processing.html#quantifiers"><i class="fa fa-check"></i><b>24.5.5</b> Quantifiers</a></li>
<li class="chapter" data-level="24.5.6" data-path="string-processing.html"><a href="string-processing.html#white-space-s"><i class="fa fa-check"></i><b>24.5.6</b> White space <code>\s</code></a></li>
<li class="chapter" data-level="24.5.7" data-path="string-processing.html"><a href="string-processing.html#quantifiers-1"><i class="fa fa-check"></i><b>24.5.7</b> Quantifiers: <code>*</code>, <code>?</code>, <code>+</code></a></li>
<li class="chapter" data-level="24.5.8" data-path="string-processing.html"><a href="string-processing.html#not"><i class="fa fa-check"></i><b>24.5.8</b> Not</a></li>
<li class="chapter" data-level="24.5.9" data-path="string-processing.html"><a href="string-processing.html#groups"><i class="fa fa-check"></i><b>24.5.9</b> Groups</a></li>
</ul></li>
<li class="chapter" data-level="24.6" data-path="string-processing.html"><a href="string-processing.html#search-and-replace-with-regex"><i class="fa fa-check"></i><b>24.6</b> Search and replace with regex</a><ul>
<li class="chapter" data-level="24.6.1" data-path="string-processing.html"><a href="string-processing.html#search-and-replace-using-groups"><i class="fa fa-check"></i><b>24.6.1</b> Search and replace using groups</a></li>
</ul></li>
<li class="chapter" data-level="24.7" data-path="string-processing.html"><a href="string-processing.html#testing-and-improving"><i class="fa fa-check"></i><b>24.7</b> Testing and improving</a></li>
<li class="chapter" data-level="24.8" data-path="string-processing.html"><a href="string-processing.html#trimming"><i class="fa fa-check"></i><b>24.8</b> Trimming</a></li>
<li class="chapter" data-level="24.9" data-path="string-processing.html"><a href="string-processing.html#changing-lettercase"><i class="fa fa-check"></i><b>24.9</b> Changing lettercase</a></li>
<li class="chapter" data-level="24.10" data-path="string-processing.html"><a href="string-processing.html#case-study-2-self-reported-heights-continued"><i class="fa fa-check"></i><b>24.10</b> Case study 2: self-reported heights (continued)</a><ul>
<li class="chapter" data-level="24.10.1" data-path="string-processing.html"><a href="string-processing.html#the-extract-function"><i class="fa fa-check"></i><b>24.10.1</b> The <code>extract</code> function</a></li>
<li class="chapter" data-level="24.10.2" data-path="string-processing.html"><a href="string-processing.html#putting-it-all-together-1"><i class="fa fa-check"></i><b>24.10.2</b> Putting it all together</a></li>
</ul></li>
<li class="chapter" data-level="24.11" data-path="string-processing.html"><a href="string-processing.html#string-splitting"><i class="fa fa-check"></i><b>24.11</b> String splitting</a></li>
<li class="chapter" data-level="24.12" data-path="string-processing.html"><a href="string-processing.html#case-study-3-extracting-tables-from-a-pdf"><i class="fa fa-check"></i><b>24.12</b> Case study 3: extracting tables from a PDF</a></li>
<li class="chapter" data-level="24.13" data-path="string-processing.html"><a href="string-processing.html#recode"><i class="fa fa-check"></i><b>24.13</b> Recoding</a></li>
<li class="chapter" data-level="24.14" data-path="string-processing.html"><a href="string-processing.html#exercises-41"><i class="fa fa-check"></i><b>24.14</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="parsing-dates-and-times.html"><a href="parsing-dates-and-times.html"><i class="fa fa-check"></i><b>25</b> Parsing dates and times</a><ul>
<li class="chapter" data-level="25.1" data-path="parsing-dates-and-times.html"><a href="parsing-dates-and-times.html#the-date-data-type"><i class="fa fa-check"></i><b>25.1</b> The date data type</a></li>
<li class="chapter" data-level="25.2" data-path="parsing-dates-and-times.html"><a href="parsing-dates-and-times.html#lubridate"><i class="fa fa-check"></i><b>25.2</b> The lubridate package</a></li>
<li class="chapter" data-level="25.3" data-path="parsing-dates-and-times.html"><a href="parsing-dates-and-times.html#exercises-42"><i class="fa fa-check"></i><b>25.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="text-mining.html"><a href="text-mining.html"><i class="fa fa-check"></i><b>26</b> Text mining</a><ul>
<li class="chapter" data-level="26.1" data-path="text-mining.html"><a href="text-mining.html#case-study-trump-tweets"><i class="fa fa-check"></i><b>26.1</b> Case study: Trump tweets</a></li>
<li class="chapter" data-level="26.2" data-path="text-mining.html"><a href="text-mining.html#text-as-data"><i class="fa fa-check"></i><b>26.2</b> Text as data</a></li>
<li class="chapter" data-level="26.3" data-path="text-mining.html"><a href="text-mining.html#sentiment-analysis"><i class="fa fa-check"></i><b>26.3</b> Sentiment analysis</a></li>
<li class="chapter" data-level="26.4" data-path="text-mining.html"><a href="text-mining.html#exercises-43"><i class="fa fa-check"></i><b>26.4</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>V Machine Learning</b></span></li>
<li class="chapter" data-level="27" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html"><i class="fa fa-check"></i><b>27</b> Introduction to machine learning</a><ul>
<li class="chapter" data-level="27.1" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#notation-1"><i class="fa fa-check"></i><b>27.1</b> Notation</a></li>
<li class="chapter" data-level="27.2" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#an-example"><i class="fa fa-check"></i><b>27.2</b> An example</a></li>
<li class="chapter" data-level="27.3" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#exercises-44"><i class="fa fa-check"></i><b>27.3</b> Exercises</a></li>
<li class="chapter" data-level="27.4" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#evaluation-metrics"><i class="fa fa-check"></i><b>27.4</b> Evaluation metrics</a><ul>
<li class="chapter" data-level="27.4.1" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#training-and-test-sets"><i class="fa fa-check"></i><b>27.4.1</b> Training and test sets</a></li>
<li class="chapter" data-level="27.4.2" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#overall-accuracy"><i class="fa fa-check"></i><b>27.4.2</b> Overall accuracy</a></li>
<li class="chapter" data-level="27.4.3" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#the-confusion-matrix"><i class="fa fa-check"></i><b>27.4.3</b> The confusion matrix</a></li>
<li class="chapter" data-level="27.4.4" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#sensitivity-and-specificity"><i class="fa fa-check"></i><b>27.4.4</b> Sensitivity and specificity</a></li>
<li class="chapter" data-level="27.4.5" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#balanced-accuracy-and-f_1-score"><i class="fa fa-check"></i><b>27.4.5</b> Balanced accuracy and <span class="math inline">\(F_1\)</span> score</a></li>
<li class="chapter" data-level="27.4.6" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#prevalence-matters-in-practice"><i class="fa fa-check"></i><b>27.4.6</b> Prevalence matters in practice</a></li>
<li class="chapter" data-level="27.4.7" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#roc-and-precision-recall-curves"><i class="fa fa-check"></i><b>27.4.7</b> ROC and precision-recall curves</a></li>
<li class="chapter" data-level="27.4.8" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#loss-function"><i class="fa fa-check"></i><b>27.4.8</b> The loss function</a></li>
</ul></li>
<li class="chapter" data-level="27.5" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#exercises-45"><i class="fa fa-check"></i><b>27.5</b> Exercises</a></li>
<li class="chapter" data-level="27.6" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#conditional-probabilities-and-expectations"><i class="fa fa-check"></i><b>27.6</b> Conditional probabilities and expectations</a><ul>
<li class="chapter" data-level="27.6.1" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#conditional-probabilities-1"><i class="fa fa-check"></i><b>27.6.1</b> Conditional probabilities</a></li>
<li class="chapter" data-level="27.6.2" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#conditional-expectations"><i class="fa fa-check"></i><b>27.6.2</b> Conditional expectations</a></li>
<li class="chapter" data-level="27.6.3" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#conditional-expectation-minimizes-squared-loss-function"><i class="fa fa-check"></i><b>27.6.3</b> Conditional expectation minimizes squared loss function</a></li>
</ul></li>
<li class="chapter" data-level="27.7" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#exercises-46"><i class="fa fa-check"></i><b>27.7</b> Exercises</a></li>
<li class="chapter" data-level="27.8" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#two-or-seven"><i class="fa fa-check"></i><b>27.8</b> Case study: is it a 2 or a 7?</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="smoothing.html"><a href="smoothing.html"><i class="fa fa-check"></i><b>28</b> Smoothing</a><ul>
<li class="chapter" data-level="28.1" data-path="smoothing.html"><a href="smoothing.html#bin-smoothing"><i class="fa fa-check"></i><b>28.1</b> Bin smoothing</a></li>
<li class="chapter" data-level="28.2" data-path="smoothing.html"><a href="smoothing.html#kernels"><i class="fa fa-check"></i><b>28.2</b> Kernels</a></li>
<li class="chapter" data-level="28.3" data-path="smoothing.html"><a href="smoothing.html#local-weighted-regression-loess"><i class="fa fa-check"></i><b>28.3</b> Local weighted regression (loess)</a><ul>
<li class="chapter" data-level="28.3.1" data-path="smoothing.html"><a href="smoothing.html#fitting-parabolas"><i class="fa fa-check"></i><b>28.3.1</b> Fitting parabolas</a></li>
<li class="chapter" data-level="28.3.2" data-path="smoothing.html"><a href="smoothing.html#beware-of-default-smoothing-parameters"><i class="fa fa-check"></i><b>28.3.2</b> Beware of default smoothing parameters</a></li>
</ul></li>
<li class="chapter" data-level="28.4" data-path="smoothing.html"><a href="smoothing.html#smoothing-ml-connection"><i class="fa fa-check"></i><b>28.4</b> Connecting smoothing to machine learning</a></li>
<li class="chapter" data-level="28.5" data-path="smoothing.html"><a href="smoothing.html#exercises-47"><i class="fa fa-check"></i><b>28.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="cross-validation.html"><a href="cross-validation.html"><i class="fa fa-check"></i><b>29</b> Cross validation</a><ul>
<li class="chapter" data-level="29.1" data-path="cross-validation.html"><a href="cross-validation.html#knn-cv-intro"><i class="fa fa-check"></i><b>29.1</b> Motivation with k-nearest neighbors</a><ul>
<li class="chapter" data-level="29.1.1" data-path="cross-validation.html"><a href="cross-validation.html#over-training"><i class="fa fa-check"></i><b>29.1.1</b> Over-training</a></li>
<li class="chapter" data-level="29.1.2" data-path="cross-validation.html"><a href="cross-validation.html#over-smoothing"><i class="fa fa-check"></i><b>29.1.2</b> Over-smoothing</a></li>
<li class="chapter" data-level="29.1.3" data-path="cross-validation.html"><a href="cross-validation.html#picking-the-k-in-knn"><i class="fa fa-check"></i><b>29.1.3</b> Picking the <span class="math inline">\(k\)</span> in kNN</a></li>
</ul></li>
<li class="chapter" data-level="29.2" data-path="cross-validation.html"><a href="cross-validation.html#mathematical-description-of-cross-validation"><i class="fa fa-check"></i><b>29.2</b> Mathematical description of cross validation</a></li>
<li class="chapter" data-level="29.3" data-path="cross-validation.html"><a href="cross-validation.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>29.3</b> K-fold cross validation</a></li>
<li class="chapter" data-level="29.4" data-path="cross-validation.html"><a href="cross-validation.html#exercises-48"><i class="fa fa-check"></i><b>29.4</b> Exercises</a></li>
<li class="chapter" data-level="29.5" data-path="cross-validation.html"><a href="cross-validation.html#bootstrap"><i class="fa fa-check"></i><b>29.5</b> Bootstrap</a></li>
<li class="chapter" data-level="29.6" data-path="cross-validation.html"><a href="cross-validation.html#exercises-49"><i class="fa fa-check"></i><b>29.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="caret.html"><a href="caret.html"><i class="fa fa-check"></i><b>30</b> The caret package</a><ul>
<li class="chapter" data-level="30.1" data-path="caret.html"><a href="caret.html#the-caret-train-functon"><i class="fa fa-check"></i><b>30.1</b> The caret <code>train</code> functon</a></li>
<li class="chapter" data-level="30.2" data-path="caret.html"><a href="caret.html#caret-cv"><i class="fa fa-check"></i><b>30.2</b> Cross validation</a></li>
<li class="chapter" data-level="30.3" data-path="caret.html"><a href="caret.html#example-fitting-with-loess"><i class="fa fa-check"></i><b>30.3</b> Example: fitting with loess</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html"><i class="fa fa-check"></i><b>31</b> Examples of algorithms</a><ul>
<li class="chapter" data-level="31.1" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#linear-regression"><i class="fa fa-check"></i><b>31.1</b> Linear regression</a><ul>
<li class="chapter" data-level="31.1.1" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#the-predict-function"><i class="fa fa-check"></i><b>31.1.1</b> The <code>predict</code> function</a></li>
</ul></li>
<li class="chapter" data-level="31.2" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#exercises-50"><i class="fa fa-check"></i><b>31.2</b> Exercises</a></li>
<li class="chapter" data-level="31.3" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#logistic-regression"><i class="fa fa-check"></i><b>31.3</b> Logistic regression</a><ul>
<li class="chapter" data-level="31.3.1" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#generalized-linear-models"><i class="fa fa-check"></i><b>31.3.1</b> Generalized linear models</a></li>
<li class="chapter" data-level="31.3.2" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#logistic-regression-with-more-than-one-predictor"><i class="fa fa-check"></i><b>31.3.2</b> Logistic regression with more than one predictor</a></li>
</ul></li>
<li class="chapter" data-level="31.4" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#exercises-51"><i class="fa fa-check"></i><b>31.4</b> Exercises</a></li>
<li class="chapter" data-level="31.5" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>31.5</b> k-nearest neighbors</a></li>
<li class="chapter" data-level="31.6" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#exercises-52"><i class="fa fa-check"></i><b>31.6</b> Exercises</a></li>
<li class="chapter" data-level="31.7" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#generative-models"><i class="fa fa-check"></i><b>31.7</b> Generative models</a><ul>
<li class="chapter" data-level="31.7.1" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#naive-bayes"><i class="fa fa-check"></i><b>31.7.1</b> Naive Bayes</a></li>
<li class="chapter" data-level="31.7.2" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#controlling-prevalence"><i class="fa fa-check"></i><b>31.7.2</b> Controlling prevalence</a></li>
<li class="chapter" data-level="31.7.3" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#quadratic-discriminant-analysis"><i class="fa fa-check"></i><b>31.7.3</b> Quadratic discriminant analysis</a></li>
<li class="chapter" data-level="31.7.4" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#linear-discriminant-analysis"><i class="fa fa-check"></i><b>31.7.4</b> Linear discriminant analysis</a></li>
<li class="chapter" data-level="31.7.5" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#connection-to-distance"><i class="fa fa-check"></i><b>31.7.5</b> Connection to distance</a></li>
</ul></li>
<li class="chapter" data-level="31.8" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#case-study-more-than-three-classes"><i class="fa fa-check"></i><b>31.8</b> Case study: more than three classes</a></li>
<li class="chapter" data-level="31.9" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#exercises-53"><i class="fa fa-check"></i><b>31.9</b> Exercises</a></li>
<li class="chapter" data-level="31.10" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#classification-and-regression-trees-cart"><i class="fa fa-check"></i><b>31.10</b> Classification and regression trees (CART)</a><ul>
<li class="chapter" data-level="31.10.1" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#the-curse-of-dimensionality"><i class="fa fa-check"></i><b>31.10.1</b> The curse of dimensionality</a></li>
<li class="chapter" data-level="31.10.2" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#cart-motivation"><i class="fa fa-check"></i><b>31.10.2</b> CART motivation</a></li>
<li class="chapter" data-level="31.10.3" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#regression-trees"><i class="fa fa-check"></i><b>31.10.3</b> Regression trees</a></li>
<li class="chapter" data-level="31.10.4" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#classification-decision-trees"><i class="fa fa-check"></i><b>31.10.4</b> Classification (decision) trees</a></li>
</ul></li>
<li class="chapter" data-level="31.11" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#random-forests"><i class="fa fa-check"></i><b>31.11</b> Random forests</a></li>
<li class="chapter" data-level="31.12" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#exercises-54"><i class="fa fa-check"></i><b>31.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html"><i class="fa fa-check"></i><b>32</b> Machine learning in practice</a><ul>
<li class="chapter" data-level="32.1" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html#preprocessing"><i class="fa fa-check"></i><b>32.1</b> Preprocessing</a></li>
<li class="chapter" data-level="32.2" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html#k-nearest-neighbor-and-random-forest"><i class="fa fa-check"></i><b>32.2</b> k-nearest neighbor and random forest</a></li>
<li class="chapter" data-level="32.3" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html#variable-importance"><i class="fa fa-check"></i><b>32.3</b> Variable importance</a></li>
<li class="chapter" data-level="32.4" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html#visual-assessments"><i class="fa fa-check"></i><b>32.4</b> Visual assessments</a></li>
<li class="chapter" data-level="32.5" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html#ensembles"><i class="fa fa-check"></i><b>32.5</b> Ensembles</a></li>
<li class="chapter" data-level="32.6" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html#exercises-55"><i class="fa fa-check"></i><b>32.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="large-datasets.html"><a href="large-datasets.html"><i class="fa fa-check"></i><b>33</b> Large datasets</a><ul>
<li class="chapter" data-level="33.1" data-path="large-datasets.html"><a href="large-datasets.html#matrix-algebra"><i class="fa fa-check"></i><b>33.1</b> Matrix algebra</a><ul>
<li class="chapter" data-level="33.1.1" data-path="large-datasets.html"><a href="large-datasets.html#notation-2"><i class="fa fa-check"></i><b>33.1.1</b> Notation</a></li>
<li class="chapter" data-level="33.1.2" data-path="large-datasets.html"><a href="large-datasets.html#converting-a-vector-to-a-matrix"><i class="fa fa-check"></i><b>33.1.2</b> Converting a vector to a matrix</a></li>
<li class="chapter" data-level="33.1.3" data-path="large-datasets.html"><a href="large-datasets.html#row-and-column-summaries"><i class="fa fa-check"></i><b>33.1.3</b> Row and column summaries</a></li>
<li class="chapter" data-level="33.1.4" data-path="large-datasets.html"><a href="large-datasets.html#apply"><i class="fa fa-check"></i><b>33.1.4</b> <code>apply</code></a></li>
<li class="chapter" data-level="33.1.5" data-path="large-datasets.html"><a href="large-datasets.html#filtering-columns-based-on-summaries"><i class="fa fa-check"></i><b>33.1.5</b> Filtering columns based on summaries</a></li>
<li class="chapter" data-level="33.1.6" data-path="large-datasets.html"><a href="large-datasets.html#indexing-with-matrices"><i class="fa fa-check"></i><b>33.1.6</b> Indexing with matrices</a></li>
<li class="chapter" data-level="33.1.7" data-path="large-datasets.html"><a href="large-datasets.html#binarizing-the-data"><i class="fa fa-check"></i><b>33.1.7</b> Binarizing the data</a></li>
<li class="chapter" data-level="33.1.8" data-path="large-datasets.html"><a href="large-datasets.html#vectorization-for-matrices"><i class="fa fa-check"></i><b>33.1.8</b> Vectorization for matrices</a></li>
<li class="chapter" data-level="33.1.9" data-path="large-datasets.html"><a href="large-datasets.html#matrix-algebra-operations"><i class="fa fa-check"></i><b>33.1.9</b> Matrix algebra operations</a></li>
</ul></li>
<li class="chapter" data-level="33.2" data-path="large-datasets.html"><a href="large-datasets.html#exercises-56"><i class="fa fa-check"></i><b>33.2</b> Exercises</a></li>
<li class="chapter" data-level="33.3" data-path="large-datasets.html"><a href="large-datasets.html#distance"><i class="fa fa-check"></i><b>33.3</b> Distance</a><ul>
<li class="chapter" data-level="33.3.1" data-path="large-datasets.html"><a href="large-datasets.html#euclidean-distance"><i class="fa fa-check"></i><b>33.3.1</b> Euclidean distance</a></li>
<li class="chapter" data-level="33.3.2" data-path="large-datasets.html"><a href="large-datasets.html#distance-in-higher-dimensions"><i class="fa fa-check"></i><b>33.3.2</b> Distance in higher dimensions</a></li>
<li class="chapter" data-level="33.3.3" data-path="large-datasets.html"><a href="large-datasets.html#euclidean-distance-example"><i class="fa fa-check"></i><b>33.3.3</b> Euclidean distance example</a></li>
<li class="chapter" data-level="33.3.4" data-path="large-datasets.html"><a href="large-datasets.html#predictor-space"><i class="fa fa-check"></i><b>33.3.4</b> Predictor space</a></li>
<li class="chapter" data-level="33.3.5" data-path="large-datasets.html"><a href="large-datasets.html#distance-between-predictors"><i class="fa fa-check"></i><b>33.3.5</b> Distance between predictors</a></li>
</ul></li>
<li class="chapter" data-level="33.4" data-path="large-datasets.html"><a href="large-datasets.html#exercises-57"><i class="fa fa-check"></i><b>33.4</b> Exercises</a></li>
<li class="chapter" data-level="33.5" data-path="large-datasets.html"><a href="large-datasets.html#dimension-reduction"><i class="fa fa-check"></i><b>33.5</b> Dimension reduction</a><ul>
<li class="chapter" data-level="33.5.1" data-path="large-datasets.html"><a href="large-datasets.html#preserving-distance"><i class="fa fa-check"></i><b>33.5.1</b> Preserving distance</a></li>
<li class="chapter" data-level="33.5.2" data-path="large-datasets.html"><a href="large-datasets.html#linear-transformations-advanced"><i class="fa fa-check"></i><b>33.5.2</b> Linear transformations (advanced)</a></li>
<li class="chapter" data-level="33.5.3" data-path="large-datasets.html"><a href="large-datasets.html#orthogonal-transformations-advanced"><i class="fa fa-check"></i><b>33.5.3</b> Orthogonal transformations (advanced)</a></li>
<li class="chapter" data-level="33.5.4" data-path="large-datasets.html"><a href="large-datasets.html#principal-component-analysis"><i class="fa fa-check"></i><b>33.5.4</b> Principal component analysis</a></li>
<li class="chapter" data-level="33.5.5" data-path="large-datasets.html"><a href="large-datasets.html#iris-example"><i class="fa fa-check"></i><b>33.5.5</b> Iris example</a></li>
<li class="chapter" data-level="33.5.6" data-path="large-datasets.html"><a href="large-datasets.html#mnist-example"><i class="fa fa-check"></i><b>33.5.6</b> MNIST example</a></li>
</ul></li>
<li class="chapter" data-level="33.6" data-path="large-datasets.html"><a href="large-datasets.html#exercises-58"><i class="fa fa-check"></i><b>33.6</b> Exercises</a></li>
<li class="chapter" data-level="33.7" data-path="large-datasets.html"><a href="large-datasets.html#recommendation-systems"><i class="fa fa-check"></i><b>33.7</b> Recommendation systems</a><ul>
<li class="chapter" data-level="33.7.1" data-path="large-datasets.html"><a href="large-datasets.html#movielens-data"><i class="fa fa-check"></i><b>33.7.1</b> Movielens data</a></li>
<li class="chapter" data-level="33.7.2" data-path="large-datasets.html"><a href="large-datasets.html#recommendation-systems-as-a-machine-learning-challenge"><i class="fa fa-check"></i><b>33.7.2</b> Recommendation systems as a machine learning challenge</a></li>
<li class="chapter" data-level="33.7.3" data-path="large-datasets.html"><a href="large-datasets.html#netflix-loss-function"><i class="fa fa-check"></i><b>33.7.3</b> Loss function</a></li>
<li class="chapter" data-level="33.7.4" data-path="large-datasets.html"><a href="large-datasets.html#a-first-model"><i class="fa fa-check"></i><b>33.7.4</b> A first model</a></li>
<li class="chapter" data-level="33.7.5" data-path="large-datasets.html"><a href="large-datasets.html#modeling-movie-effects"><i class="fa fa-check"></i><b>33.7.5</b> Modeling movie effects</a></li>
<li class="chapter" data-level="33.7.6" data-path="large-datasets.html"><a href="large-datasets.html#user-effects"><i class="fa fa-check"></i><b>33.7.6</b> User effects</a></li>
</ul></li>
<li class="chapter" data-level="33.8" data-path="large-datasets.html"><a href="large-datasets.html#exercises-59"><i class="fa fa-check"></i><b>33.8</b> Exercises</a></li>
<li class="chapter" data-level="33.9" data-path="large-datasets.html"><a href="large-datasets.html#regularization"><i class="fa fa-check"></i><b>33.9</b> Regularization</a><ul>
<li class="chapter" data-level="33.9.1" data-path="large-datasets.html"><a href="large-datasets.html#motivation"><i class="fa fa-check"></i><b>33.9.1</b> Motivation</a></li>
<li class="chapter" data-level="33.9.2" data-path="large-datasets.html"><a href="large-datasets.html#penalized-least-squares"><i class="fa fa-check"></i><b>33.9.2</b> Penalized least squares</a></li>
<li class="chapter" data-level="33.9.3" data-path="large-datasets.html"><a href="large-datasets.html#choosing-the-penalty-terms"><i class="fa fa-check"></i><b>33.9.3</b> Choosing the penalty terms</a></li>
</ul></li>
<li class="chapter" data-level="33.10" data-path="large-datasets.html"><a href="large-datasets.html#exercises-60"><i class="fa fa-check"></i><b>33.10</b> Exercises</a></li>
<li class="chapter" data-level="33.11" data-path="large-datasets.html"><a href="large-datasets.html#matrix-factorization"><i class="fa fa-check"></i><b>33.11</b> Matrix factorization</a><ul>
<li class="chapter" data-level="33.11.1" data-path="large-datasets.html"><a href="large-datasets.html#factors-analysis"><i class="fa fa-check"></i><b>33.11.1</b> Factors analysis</a></li>
<li class="chapter" data-level="33.11.2" data-path="large-datasets.html"><a href="large-datasets.html#connection-to-svd-and-pca"><i class="fa fa-check"></i><b>33.11.2</b> Connection to SVD and PCA</a></li>
</ul></li>
<li class="chapter" data-level="33.12" data-path="large-datasets.html"><a href="large-datasets.html#exercises-61"><i class="fa fa-check"></i><b>33.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>34</b> Clustering</a><ul>
<li class="chapter" data-level="34.1" data-path="clustering.html"><a href="clustering.html#hierarchical-clustering"><i class="fa fa-check"></i><b>34.1</b> Hierarchical clustering</a></li>
<li class="chapter" data-level="34.2" data-path="clustering.html"><a href="clustering.html#k-means"><i class="fa fa-check"></i><b>34.2</b> k-means</a></li>
<li class="chapter" data-level="34.3" data-path="clustering.html"><a href="clustering.html#heatmaps"><i class="fa fa-check"></i><b>34.3</b> Heatmaps</a></li>
<li class="chapter" data-level="34.4" data-path="clustering.html"><a href="clustering.html#filtering-features"><i class="fa fa-check"></i><b>34.4</b> Filtering features</a></li>
<li class="chapter" data-level="34.5" data-path="clustering.html"><a href="clustering.html#exercises-62"><i class="fa fa-check"></i><b>34.5</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>VI Productivity Tools</b></span></li>
<li class="chapter" data-level="35" data-path="introduction-to-productivity-tools.html"><a href="introduction-to-productivity-tools.html"><i class="fa fa-check"></i><b>35</b> Introduction to productivity tools</a></li>
<li class="chapter" data-level="36" data-path="installing-r-rstudio.html"><a href="installing-r-rstudio.html"><i class="fa fa-check"></i><b>36</b> Installing R and RStudio</a><ul>
<li class="chapter" data-level="36.1" data-path="installing-r-rstudio.html"><a href="installing-r-rstudio.html#installing-r"><i class="fa fa-check"></i><b>36.1</b> Installing R</a></li>
<li class="chapter" data-level="36.2" data-path="installing-r-rstudio.html"><a href="installing-r-rstudio.html#installing-rstudio"><i class="fa fa-check"></i><b>36.2</b> Installing RStudio</a></li>
</ul></li>
<li class="chapter" data-level="37" data-path="accessing-the-terminal-and-installing-git.html"><a href="accessing-the-terminal-and-installing-git.html"><i class="fa fa-check"></i><b>37</b> Accessing the terminal and installing Git</a><ul>
<li class="chapter" data-level="37.1" data-path="accessing-the-terminal-and-installing-git.html"><a href="accessing-the-terminal-and-installing-git.html#terminal-on-mac"><i class="fa fa-check"></i><b>37.1</b> Accessing the terminal on a Mac</a></li>
<li class="chapter" data-level="37.2" data-path="accessing-the-terminal-and-installing-git.html"><a href="accessing-the-terminal-and-installing-git.html#installing-git-on-the-mac"><i class="fa fa-check"></i><b>37.2</b> Installing Git on the Mac</a></li>
<li class="chapter" data-level="37.3" data-path="accessing-the-terminal-and-installing-git.html"><a href="accessing-the-terminal-and-installing-git.html#installing-git-and-git-bash-on-windows"><i class="fa fa-check"></i><b>37.3</b> Installing Git and Git Bash on Windows</a></li>
<li class="chapter" data-level="37.4" data-path="accessing-the-terminal-and-installing-git.html"><a href="accessing-the-terminal-and-installing-git.html#terminal-on-windows"><i class="fa fa-check"></i><b>37.4</b> Accessing the terminal on Windows</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="unix.html"><a href="unix.html"><i class="fa fa-check"></i><b>38</b> Organizing with Unix</a><ul>
<li class="chapter" data-level="38.1" data-path="unix.html"><a href="unix.html#naming-convention"><i class="fa fa-check"></i><b>38.1</b> Naming convention</a></li>
<li class="chapter" data-level="38.2" data-path="unix.html"><a href="unix.html#the-terminal"><i class="fa fa-check"></i><b>38.2</b> The terminal</a></li>
<li class="chapter" data-level="38.3" data-path="unix.html"><a href="unix.html#filesystem"><i class="fa fa-check"></i><b>38.3</b> The filesystem</a><ul>
<li class="chapter" data-level="38.3.1" data-path="unix.html"><a href="unix.html#directories-and-subdirectories"><i class="fa fa-check"></i><b>38.3.1</b> Directories and subdirectories</a></li>
<li class="chapter" data-level="38.3.2" data-path="unix.html"><a href="unix.html#the-home-directory"><i class="fa fa-check"></i><b>38.3.2</b> The home directory</a></li>
<li class="chapter" data-level="38.3.3" data-path="unix.html"><a href="unix.html#working-directory"><i class="fa fa-check"></i><b>38.3.3</b> Working directory</a></li>
<li class="chapter" data-level="38.3.4" data-path="unix.html"><a href="unix.html#paths"><i class="fa fa-check"></i><b>38.3.4</b> Paths</a></li>
</ul></li>
<li class="chapter" data-level="38.4" data-path="unix.html"><a href="unix.html#unix-commands"><i class="fa fa-check"></i><b>38.4</b> Unix commands</a><ul>
<li class="chapter" data-level="38.4.1" data-path="unix.html"><a href="unix.html#ls-listing-directory-content"><i class="fa fa-check"></i><b>38.4.1</b> <code>ls</code>: Listing directory content</a></li>
<li class="chapter" data-level="38.4.2" data-path="unix.html"><a href="unix.html#mkdir-and-rmdir-make-and-remove-a-directory"><i class="fa fa-check"></i><b>38.4.2</b> <code>mkdir</code> and <code>rmdir</code>: make and remove a directory</a></li>
<li class="chapter" data-level="38.4.3" data-path="unix.html"><a href="unix.html#cd-navigating-the-filesystem-by-changing-directories"><i class="fa fa-check"></i><b>38.4.3</b> <code>cd</code>: navigating the filesystem by changing directories</a></li>
</ul></li>
<li class="chapter" data-level="38.5" data-path="unix.html"><a href="unix.html#some-examples"><i class="fa fa-check"></i><b>38.5</b> Some examples</a></li>
<li class="chapter" data-level="38.6" data-path="unix.html"><a href="unix.html#more-unix-commands"><i class="fa fa-check"></i><b>38.6</b> More Unix commands</a><ul>
<li class="chapter" data-level="38.6.1" data-path="unix.html"><a href="unix.html#mv-moving-files"><i class="fa fa-check"></i><b>38.6.1</b> <code>mv</code>: moving files</a></li>
<li class="chapter" data-level="38.6.2" data-path="unix.html"><a href="unix.html#cp-copying-files"><i class="fa fa-check"></i><b>38.6.2</b> <code>cp</code>: copying files</a></li>
<li class="chapter" data-level="38.6.3" data-path="unix.html"><a href="unix.html#rm-removing-files"><i class="fa fa-check"></i><b>38.6.3</b> <code>rm</code>: removing files</a></li>
<li class="chapter" data-level="38.6.4" data-path="unix.html"><a href="unix.html#less-looking-at-a-file"><i class="fa fa-check"></i><b>38.6.4</b> <code>less</code>: looking at a file</a></li>
</ul></li>
<li class="chapter" data-level="38.7" data-path="unix.html"><a href="unix.html#prep-project"><i class="fa fa-check"></i><b>38.7</b> Preparing for a data science project</a></li>
<li class="chapter" data-level="38.8" data-path="unix.html"><a href="unix.html#advanced-unix"><i class="fa fa-check"></i><b>38.8</b> Advanced Unix</a><ul>
<li class="chapter" data-level="38.8.1" data-path="unix.html"><a href="unix.html#arguments"><i class="fa fa-check"></i><b>38.8.1</b> Arguments</a></li>
<li class="chapter" data-level="38.8.2" data-path="unix.html"><a href="unix.html#getting-help"><i class="fa fa-check"></i><b>38.8.2</b> Getting help</a></li>
<li class="chapter" data-level="38.8.3" data-path="unix.html"><a href="unix.html#pipes"><i class="fa fa-check"></i><b>38.8.3</b> Pipes</a></li>
<li class="chapter" data-level="38.8.4" data-path="unix.html"><a href="unix.html#wild-cards"><i class="fa fa-check"></i><b>38.8.4</b> Wild cards</a></li>
<li class="chapter" data-level="38.8.5" data-path="unix.html"><a href="unix.html#environment-variables"><i class="fa fa-check"></i><b>38.8.5</b> Environment variables</a></li>
<li class="chapter" data-level="38.8.6" data-path="unix.html"><a href="unix.html#shells"><i class="fa fa-check"></i><b>38.8.6</b> Shells</a></li>
<li class="chapter" data-level="38.8.7" data-path="unix.html"><a href="unix.html#executables"><i class="fa fa-check"></i><b>38.8.7</b> Executables</a></li>
<li class="chapter" data-level="38.8.8" data-path="unix.html"><a href="unix.html#permissions-and-file-types"><i class="fa fa-check"></i><b>38.8.8</b> Permissions and file types</a></li>
<li class="chapter" data-level="38.8.9" data-path="unix.html"><a href="unix.html#commands-you-should-learn"><i class="fa fa-check"></i><b>38.8.9</b> Commands you should learn</a></li>
<li class="chapter" data-level="38.8.10" data-path="unix.html"><a href="unix.html#file-manipulation-in-r"><i class="fa fa-check"></i><b>38.8.10</b> File manipulation in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="39" data-path="git.html"><a href="git.html"><i class="fa fa-check"></i><b>39</b> Git and GitHub</a><ul>
<li class="chapter" data-level="39.1" data-path="git.html"><a href="git.html#why-use-git-and-github"><i class="fa fa-check"></i><b>39.1</b> Why use Git and GitHub?</a></li>
<li class="chapter" data-level="39.2" data-path="git.html"><a href="git.html#github-accounts"><i class="fa fa-check"></i><b>39.2</b> GitHub accounts</a></li>
<li class="chapter" data-level="39.3" data-path="git.html"><a href="git.html#github-repos"><i class="fa fa-check"></i><b>39.3</b> GitHub repositories</a></li>
<li class="chapter" data-level="39.4" data-path="git.html"><a href="git.html#git-overview"><i class="fa fa-check"></i><b>39.4</b> Overview of Git</a><ul>
<li class="chapter" data-level="39.4.1" data-path="git.html"><a href="git.html#clone"><i class="fa fa-check"></i><b>39.4.1</b> Clone</a></li>
</ul></li>
<li class="chapter" data-level="39.5" data-path="git.html"><a href="git.html#init"><i class="fa fa-check"></i><b>39.5</b> Initializing a Git directory</a></li>
<li class="chapter" data-level="39.6" data-path="git.html"><a href="git.html#rstudio-git"><i class="fa fa-check"></i><b>39.6</b> Using Git and GitHub in RStudio</a></li>
</ul></li>
<li class="chapter" data-level="40" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html"><i class="fa fa-check"></i><b>40</b> Reproducible projects with RStudio and R markdown</a><ul>
<li class="chapter" data-level="40.1" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#rstudio-projects"><i class="fa fa-check"></i><b>40.1</b> RStudio projects</a></li>
<li class="chapter" data-level="40.2" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#r-markdown"><i class="fa fa-check"></i><b>40.2</b> R markdown</a><ul>
<li class="chapter" data-level="40.2.1" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#the-header"><i class="fa fa-check"></i><b>40.2.1</b> The header</a></li>
<li class="chapter" data-level="40.2.2" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#r-code-chunks"><i class="fa fa-check"></i><b>40.2.2</b> R code chunks</a></li>
<li class="chapter" data-level="40.2.3" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#global-options"><i class="fa fa-check"></i><b>40.2.3</b> Global options</a></li>
<li class="chapter" data-level="40.2.4" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#knitr"><i class="fa fa-check"></i><b>40.2.4</b> knitR</a></li>
<li class="chapter" data-level="40.2.5" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#more-on-r-markdown"><i class="fa fa-check"></i><b>40.2.5</b> More on R markdown</a></li>
</ul></li>
<li class="chapter" data-level="40.3" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#organizing"><i class="fa fa-check"></i><b>40.3</b> Organizing a data science project</a><ul>
<li class="chapter" data-level="40.3.1" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#create-directories-in-unix"><i class="fa fa-check"></i><b>40.3.1</b> Create directories in Unix</a></li>
<li class="chapter" data-level="40.3.2" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#create-an-rstudio-project"><i class="fa fa-check"></i><b>40.3.2</b> Create an RStudio project</a></li>
<li class="chapter" data-level="40.3.3" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#edit-some-r-scripts"><i class="fa fa-check"></i><b>40.3.3</b> Edit some R scripts</a></li>
<li class="chapter" data-level="40.3.4" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#create-some-more-directories-using-unix"><i class="fa fa-check"></i><b>40.3.4</b> Create some more directories using Unix</a></li>
<li class="chapter" data-level="40.3.5" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#add-a-readme-file"><i class="fa fa-check"></i><b>40.3.5</b> Add a README file</a></li>
<li class="chapter" data-level="40.3.6" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#initializing-a-git-directory"><i class="fa fa-check"></i><b>40.3.6</b> Initializing a Git directory</a></li>
<li class="chapter" data-level="40.3.7" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#add-commit-and-push-files-using-rstudio"><i class="fa fa-check"></i><b>40.3.7</b> Add, commit, and push files using RStudio</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="random-variables" class="section level1">
<h1><span class="header-section-number">Chapter 14</span> Random variables</h1>
<p>In data science, we often deal with data that is affected by chance in some way: the data comes from a random sample, the data is affected by measurement error, or the data measures some outcome that is random in nature. Being able to quantify the uncertainty introduced by randomness is one of the most important jobs of a data analyst. Statistical inference offers a framework, as well as several practical tools, for doing this. The first step is to learn how to mathematically describe random variables.</p>
<p>In this chapter, we introduce random variables and their properties starting with their application to games of chance. We then describe some of the events surrounding the financial crisis of 2007-2008<a href="#fn46" class="footnoteRef" id="fnref46"><sup>46</sup></a> using probability theory. This financial crisis was in part caused by underestimating the risk of certain securities<a href="#fn47" class="footnoteRef" id="fnref47"><sup>47</sup></a> sold by financial institutions. Specifically, the risks of mortgage-backed securities (MBS) and collateralized debt obligations (CDO) were grossly underestimated. These assets were sold at prices that assumed most homeowners would make their monthly payments, and the probability of this not occurring was calculated as being low. A combination of factors resulted in many more defaults than were expected, which led to a price crash of these securities. As a consequence, banks lost so much money that they needed government bailouts to avoid closing down completely.</p>
<div id="random-variables-1" class="section level2">
<h2><span class="header-section-number">14.1</span> Random variables</h2>
<p>Random variables are numeric outcomes resulting from random processes. We can easily generate random variables using some of the simple examples we have shown. For example, define <code>X</code> to be 1 if a bead is blue and red otherwise:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beads &lt;-<span class="st"> </span><span class="kw">rep</span>( <span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>), <span class="dt">times =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))
X &lt;-<span class="st"> </span><span class="kw">ifelse</span>(<span class="kw">sample</span>(beads, <span class="dv">1</span>) <span class="op">==</span><span class="st"> &quot;blue&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)</code></pre></div>
<p>Here <code>X</code> is a random variable: every time we select a new bead the outcome changes randomly. See below:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ifelse</span>(<span class="kw">sample</span>(beads, <span class="dv">1</span>) <span class="op">==</span><span class="st"> &quot;blue&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)
<span class="co">#&gt; [1] 1</span>
<span class="kw">ifelse</span>(<span class="kw">sample</span>(beads, <span class="dv">1</span>) <span class="op">==</span><span class="st"> &quot;blue&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)
<span class="co">#&gt; [1] 0</span>
<span class="kw">ifelse</span>(<span class="kw">sample</span>(beads, <span class="dv">1</span>) <span class="op">==</span><span class="st"> &quot;blue&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)
<span class="co">#&gt; [1] 0</span></code></pre></div>
<p>Sometimes it’s 1 and sometimes it’s 0.</p>
</div>
<div id="sampling-models" class="section level2">
<h2><span class="header-section-number">14.2</span> Sampling models</h2>
<p>Many data generation procedures, those that produce the data we study, can be modeled quite well as draws from an urn. For instance, we can model the process of polling likely voters as drawing 0s (Republicans) and 1s (Democrats) from an urn containing the 0 and 1 code for all likely voters. In epidemiological studies, we often assume that the subjects in our study are a random sample from the population of interest. The data related to a specific outcome can be modeled as a random sample from an urn containing the outcome for the entire population of interest. Similarly, in experimental research, we often assume that the individual organisms we are studying, for example worms, flies, or mice, are a random sample from a larger population. Randomized experiments can also be modeled by draws from an urn given the way individuals are assigned into groups: when getting assigned, you draw your group at random. Sampling models are therefore ubiquitous in data science. Casino games offer a plethora of examples of real-world situations in which sampling models are used to answer specific questions. We will therefore start with such examples.</p>
<p>Suppose a very small casino hires you to consult on whether they should set up roulette wheels. To keep the example simple, we will assume that 1,000 people will play and that the only game you can play on the roulette wheel is to bet on red or black. The casino wants you to predict how much money they will make or lose. They want a range of values and, in particular, they want to know what’s the chance of losing money. If this probability is too high, they will pass on installing roulette wheels.</p>
<p>We are going to define a random variable <span class="math inline">\(S\)</span> that will represent the casino’s total winnings. Let’s start by constructing the urn. A roulette wheel has 18 red pockets, 18 black pockets and 2 green ones. So playing a color in one game of roulette is equivalent to drawing from this urn:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">color &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;Red&quot;</span>, <span class="st">&quot;Green&quot;</span>), <span class="kw">c</span>(<span class="dv">18</span>, <span class="dv">18</span>, <span class="dv">2</span>))</code></pre></div>
<p>The 1,000 outcomes from 1,000 people playing are independent draws from this urn. If red comes up, the gambler wins and the casino loses a dollar, so we draw a -$1. Otherwise, the casino wins a dollar and we draw a $1. To construct our random variable <span class="math inline">\(S\)</span>, we can use this code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">1000</span>
X &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">ifelse</span>(color <span class="op">==</span><span class="st"> &quot;Red&quot;</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>),  n, <span class="dt">replace =</span> <span class="ot">TRUE</span>)
X[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>]
<span class="co">#&gt;  [1] -1  1  1 -1 -1 -1  1  1  1  1</span></code></pre></div>
<p>Because we know the proportions of 1s and -1s, we can generate the draws with one line of code, without defining <code>color</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">X &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), n, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">9</span><span class="op">/</span><span class="dv">19</span>, <span class="dv">10</span><span class="op">/</span><span class="dv">19</span>))</code></pre></div>
<p>We call this a <strong>sampling model</strong> since we are modeling the random behavior of roulette with the sampling of draws from an urn. The total winnings <span class="math inline">\(S\)</span> is simply the sum of these 1,000 independent draws:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">X &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), n, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">9</span><span class="op">/</span><span class="dv">19</span>, <span class="dv">10</span><span class="op">/</span><span class="dv">19</span>))
S &lt;-<span class="st"> </span><span class="kw">sum</span>(X)
S
<span class="co">#&gt; [1] 22</span></code></pre></div>
</div>
<div id="the-probability-distribution-of-a-random-variable" class="section level2">
<h2><span class="header-section-number">14.3</span> The probability distribution of a random variable</h2>
<p>If you run the code above, you see that <span class="math inline">\(S\)</span> changes every time. This is, of course, because <span class="math inline">\(S\)</span> is a <strong>random variable</strong>. The probability distribution of a random variable tells us the probability of the observed value falling at any given interval. So, for example, if we want to know the probability that we lose money, we are asking the probability that <span class="math inline">\(S\)</span> is in the interval <span class="math inline">\(S&lt;0\)</span>.</p>
<p>Note that if we can define a cumulative distribution function <span class="math inline">\(F(a) = \mbox{Pr}(S\leq a)\)</span>, then we will be able to answer any question related to the probability of events defined by our random variable <span class="math inline">\(S\)</span>, including the event <span class="math inline">\(S&lt;0\)</span>. We call this <span class="math inline">\(F\)</span> the random variable’s <em>distribution function</em>.</p>
<p>We can estimate the distribution function for the random variable <span class="math inline">\(S\)</span> by using a Monte Carlo simulation to generate many realizations of the random variable. With this code, we run the experiment of having 1,000 people play roulette, over and over, specifically <span class="math inline">\(B = 10,000\)</span> times:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">1000</span>
B &lt;-<span class="st"> </span><span class="dv">10000</span>
roulette_winnings &lt;-<span class="st"> </span><span class="cf">function</span>(n){
  X &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), n, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">9</span><span class="op">/</span><span class="dv">19</span>, <span class="dv">10</span><span class="op">/</span><span class="dv">19</span>))
  <span class="kw">sum</span>(X)
}
S &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, <span class="kw">roulette_winnings</span>(n))</code></pre></div>
<p>Now we can ask the following: in our simulations, how often did we get sums less than or equal to <code>a</code>?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(S <span class="op">&lt;=</span><span class="st"> </span>a)</code></pre></div>
<p>This will be a very good approximation of <span class="math inline">\(F(a)\)</span> and we can easily answer the casino’s question: how likely is it that we will lose money? We can see it is quite low:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(S<span class="op">&lt;</span><span class="dv">0</span>)
<span class="co">#&gt; [1] 0.0456</span></code></pre></div>
<p>We can visualize the distribution of <span class="math inline">\(S\)</span> by creating a histogram showing the probability <span class="math inline">\(F(b)-F(a)\)</span> for several intervals <span class="math inline">\((a,b]\)</span>:</p>
<p><img src="book_files/figure-html/normal-approximates-distribution-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>We see that the distribution appears to be approximately normal. A qq-plot will confirm that the normal approximation is close to a perfect approximation for this distribution. If, in fact, the distribution is normal, then all we need to define the distribution is the average and the standard deviation. Because we have the original values from which the distribution is created, we can easily compute these with <code>mean(S)</code> and <code>sd(S)</code>. The blue curve you see added to the histogram above is a normal density with this average and standard deviation.</p>
<p>This average and this standard deviation have special names. They are referred to as the <em>expected value</em> and <em>standard error</em> of the random variable <span class="math inline">\(S\)</span>. We will say more about these in the next section.</p>
<p>Statistical theory provides a way to derive the distribution of random variables defined as independent random draws from an urn. Specifically, in our example above, we can show that <span class="math inline">\((S+n)/2\)</span> follows a binomial distribution. We therefore do not need to run for Monte Carlo simulations to know the probability distribution of <span class="math inline">\(S\)</span>. We did this for illustrative purposes.</p>
<p>We can use the function <code>dbinom</code> and <code>pbinom</code> to compute the probabilities exactly. For example, to compute <span class="math inline">\(\mbox{Pr}(S &lt; 0)\)</span> we note that:</p>
<p><span class="math display">\[\mbox{Pr}(S &lt; 0) = \mbox{Pr}((S+n)/2 &lt; (0+n)/2)\]</span></p>
<p>and we can use the <code>pbinom</code> to compute <span class="math display">\[\mbox{Pr}(S \leq 0)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">1000</span>
<span class="kw">pbinom</span>(n<span class="op">/</span><span class="dv">2</span>, <span class="dt">size =</span> n, <span class="dt">prob =</span> <span class="dv">10</span><span class="op">/</span><span class="dv">19</span>)
<span class="co">#&gt; [1] 0.0511</span></code></pre></div>
<p>Because this is a discrete probability function, to get <span class="math inline">\(\mbox{Pr}(S &lt; 0)\)</span> rather than <span class="math inline">\(\mbox{Pr}(S \leq 0)\)</span>, we write:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pbinom</span>(n<span class="op">/</span><span class="dv">2</span><span class="op">-</span><span class="dv">1</span>, <span class="dt">size =</span> n, <span class="dt">prob =</span> <span class="dv">10</span><span class="op">/</span><span class="dv">19</span>)
<span class="co">#&gt; [1] 0.0448</span></code></pre></div>
<p>For the details of the binomial distribution, you can consult any basic probability book or even Wikipedia<a href="#fn48" class="footnoteRef" id="fnref48"><sup>48</sup></a>.</p>
<p>Here we do not cover these details. Instead, we will discuss an incredibly useful approximation provided by mathematical theory that applies generally to sums and averages of draws from any urn: the Central Limit Theorem (CLT).</p>
</div>
<div id="distributions-versus-probability-distributions" class="section level2">
<h2><span class="header-section-number">14.4</span> Distributions versus probability distributions</h2>
<p>Before we continue, let’s make an important distinction and connection between the distribution of a list of numbers and a probability distribution. In the visualization chapter, we described how any list of numbers <span class="math inline">\(x_1,\dots,x_n\)</span> has a distribution. The definition is quite straightforward. We define <span class="math inline">\(F(a)\)</span> as the function that tells us what proportion of the list is less than or equal to <span class="math inline">\(a\)</span>. Because they are useful summaries when the distribution is approximately normal, we define the average and standard deviation. These are defined with a straightforward operation of the vector containing the list of numbers <code>x</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m &lt;-<span class="st"> </span><span class="kw">sum</span>(x)<span class="op">/</span><span class="kw">length</span>(x)
s &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">sum</span>((x <span class="op">-</span><span class="st"> </span>m)<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(x))</code></pre></div>
<p>A random variable <span class="math inline">\(X\)</span> has a distribution function. To define this, we do not need a list of numbers. It is a theoretical concept. In this case, we define the distribution as the <span class="math inline">\(F(a)\)</span> that answers the question: what is the probability that <span class="math inline">\(X\)</span> is less than or equal to <span class="math inline">\(a\)</span>? There is no list of numbers.</p>
<p>However, if <span class="math inline">\(X\)</span> is defined by drawing from an urn with numbers in it, then there is a list: the list of numbers inside the urn. In this case, the distribution of that list is the probability distribution of <span class="math inline">\(X\)</span> and the average and standard deviation of that list are the expected value and standard error of the random variable.</p>
<p>Another way to think about it that does not involve an urn is to run a Monte Carlo simulation and generate a very large list of outcomes of <span class="math inline">\(X\)</span>. These outcomes are a list of numbers. The distribution of this list will be a very good approximation of the probability distribution of <span class="math inline">\(X\)</span>. The longer the list, the better the approximation. The average and standard deviation of this list will approximate the expected value and standard error of the random variable.</p>
</div>
<div id="notation-for-random-variables" class="section level2">
<h2><span class="header-section-number">14.5</span> Notation for random variables</h2>
<p>In statistical textbooks, upper case letters are used to denote random variables and we follow this convention here. Lower case letters are used for observed values. You will see some notation that includes both. For example, you will see events defined as <span class="math inline">\(X \leq x\)</span>. Here <span class="math inline">\(X\)</span> is a random variable, making it a random event, and <span class="math inline">\(x\)</span> is an arbitrary value and not random. So, for example, <span class="math inline">\(X\)</span> might represent the number on a die roll and <span class="math inline">\(x\)</span> will represent an actual value we see 1, 2, 3, 4, 5, or 6. So in this case, the probability of <span class="math inline">\(X=x\)</span> is 1/6 regardless of the observed value <span class="math inline">\(x\)</span>. This notation is a bit strange because, when we ask questions about probability, <span class="math inline">\(X\)</span> is not an observed quantity. Instead, it’s a random quantity that we will see in the future. We can talk about what we expect it to be, what values are probable, but not what it is. But once we have data, we do see a realization of <span class="math inline">\(X\)</span>. So data scientists talk of what could have been after we see what actually happened.</p>
</div>
<div id="the-expected-value-and-standard-error" class="section level2">
<h2><span class="header-section-number">14.6</span> The expected value and standard error</h2>
<p>We have described sampling models for draws. We will now go over the mathematical theory that lets us approximate the probability distributions for the sum of draws. Once we do this, we will be able to help the casino predict how much money they will make. The same approach we use for the sum of draws will be useful for describing the distribution of averages and proportion which we will need to understand how polls work.</p>
<p>The first important concept to learn is the <em>expected value</em>. In statistics books, it is common to use letter <span class="math inline">\(\mbox{E}\)</span> like this:</p>
<p><span class="math display">\[\mbox{E}[X]\]</span></p>
<p>to denote the expected value of the random variable <span class="math inline">\(X\)</span>.</p>
<p>A random variable will vary around its expected value in a way that if you take the average of many, many draws, the average of the draws will approximate the expected value, getting closer and closer the more draws you take.</p>
<p>Theoretical statistics provides techniques that facilitate the calculation of expected values in different circumstances. For example, a useful formula tells us that the <em>expected value of a random variable defined by one draw is the average of the numbers in the urn</em>. In the urn used to model betting on red in roulette, we have 20 one dollars and 18 negative one dollars. The expected value is thus:</p>
<p><span class="math display">\[
\mbox{E}[X] = (20 + -18)/38
\]</span></p>
<p>which is about 5 cents. It is a bit counterintuitive to say that <span class="math inline">\(X\)</span> varies around 0.05, when the only values it takes is 1 and -1. One way to make sense of the expected value in this context is by realizing that if we play the game over and over, the casino wins, on average, 5 cents per game. A Monte Carlo simulation confirms this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">B &lt;-<span class="st"> </span><span class="dv">10</span><span class="op">^</span><span class="dv">6</span>
x &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), B, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">9</span><span class="op">/</span><span class="dv">19</span>, <span class="dv">10</span><span class="op">/</span><span class="dv">19</span>))
<span class="kw">mean</span>(x)
<span class="co">#&gt; [1] 0.0517</span></code></pre></div>
<p>In general, if the urn has two possible outcomes, say <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, with proportions <span class="math inline">\(p\)</span> and <span class="math inline">\(1-p\)</span> respectively, the average is:</p>
<p><span class="math display">\[\mbox{E}[X] = ap + b(1-p)\]</span></p>
<p>To see this, notice that if there are <span class="math inline">\(n\)</span> beads in the urn, then we have <span class="math inline">\(np\)</span> <span class="math inline">\(a\)</span>s and <span class="math inline">\(n(1-p)\)</span> <span class="math inline">\(b\)</span>s and because the average is the sum, <span class="math inline">\(n\times a \times p + n\times b \times (1-p)\)</span>, divided by the total <span class="math inline">\(n\)</span>, we get that the average is <span class="math inline">\(ap + b(1-p)\)</span>.</p>
<p>Now the reason we define the expected value is because this mathematical definition turns out to be useful for approximating the probability distributions of sum, which then is useful for describing the distribution of averages and proportions. The first useful fact is that the <em>expected value of the sum of the draws</em> is:</p>
<p><span class="math display">\[
\mbox{}\mbox{number of draws } \times \mbox{ average of the numbers in the urn}
\]</span></p>
<p>So if 1,000 people play roulette, the casino expects to win, on average, about 1,000 <span class="math inline">\(\times\)</span> $0.05 = $50. But this is an expected value. How different can one observation be from the expected value? The casino really needs to know this. What is the range of possibilities? If negative numbers are too likely, they will not install roulette wheels. Statistical theory once again answers this question. The <em>standard error</em> (SE) gives us an idea of the size of the variation around the expected value. In statistics books, it’s common to use:</p>
<p><span class="math display">\[\mbox{SE}[X]\]</span></p>
<p>to denote the standard error of a random variable.</p>
<p><strong>If our draws are independent</strong>, then the <em>standard error of the sum</em> is given by the equation:</p>
<p><span class="math display">\[
\sqrt{\mbox{number of draws }} \times \mbox{ standard deviation of the numbers in the urn}
\]</span></p>
<p>Using the definition of standard deviation, we can derive, with a bit of math, that if an urn contains two values <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> with proportions <span class="math inline">\(p\)</span> and <span class="math inline">\((1-p)\)</span>, respectively, the standard deviation is:</p>
<p><span class="math display">\[\mid b - a \mid \sqrt{p(1-p)}.\]</span></p>
<p>So in our roulette example, the standard deviation of the values inside the urn is: <span class="math inline">\(\mid 1 - (-1) \mid \sqrt{10/19 \times 9/19}\)</span> or:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">90</span>)<span class="op">/</span><span class="dv">19</span>
<span class="co">#&gt; [1] 0.999</span></code></pre></div>
<p>The standard error tells us the typical difference between a random variable and its expectation. Since one draw is obviously the sum of just one draw, we can use the formula above to calculate that the random variable defined by one draw has an expected value of 0.05 and a standard error of about 1. This makes sense since we either get 1 or -1, with 1 slightly favored over -1.</p>
<p>Using the formula above, the sum of 1,000 people playing has standard error of about $32:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">1000</span>
<span class="kw">sqrt</span>(n) <span class="op">*</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">90</span>)<span class="op">/</span><span class="dv">19</span>
<span class="co">#&gt; [1] 31.6</span></code></pre></div>
<p>As a result, when 1,000 people bet on red, the casino is expected to win $50 with a standard error of $32. It therefore seems like a safe bet. But we still haven’t answered the question: how likely is it to lose money? Here the CLT will help.</p>
<p><strong>Advanced note</strong>: Before continuing we should point out that exact probability calculations for the casino winnings can be performed with the binomial distribution. However, here we focus on the CLT, which can be generally applied to sums of random variables in a way that the binomial distribution can’t.</p>
<div id="population-sd-versus-the-sample-sd" class="section level3">
<h3><span class="header-section-number">14.6.1</span> Population SD versus the sample SD</h3>
<p>The standard deviation of a list <code>x</code> (below we use heights as an example) is defined as the square root of the average of the squared differences:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dslabs)
x &lt;-<span class="st"> </span>heights<span class="op">$</span>height
m &lt;-<span class="st"> </span><span class="kw">mean</span>(x)
s &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">mean</span>((x<span class="op">-</span>m)<span class="op">^</span><span class="dv">2</span>))</code></pre></div>
<p>Using mathematical notation we write:</p>
<p><span class="math display">\[
\mu = \frac{1}{n} \sum_{i=1}^n x_i \\
\sigma =  \sqrt{\frac{1}{n} \sum_{i=1}^n (x_i - \mu)^2}
\]</span></p>
<p>However, be aware that the <code>sd</code> function returns a slightly different result:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">identical</span>(s, <span class="kw">sd</span>(x))
<span class="co">#&gt; [1] FALSE</span>
s<span class="op">-</span><span class="kw">sd</span>(x)
<span class="co">#&gt; [1] -0.00194</span></code></pre></div>
<p>This is because the <code>sd</code> function R does not return the <code>sd</code> of the list, but rather uses a formula that estimates standard deviations of a population from a random sample <span class="math inline">\(X_1, \dots, X_N\)</span> which, for reasons not discussed here, divide the sum of squares by the <span class="math inline">\(N-1\)</span>.</p>
<p><span class="math display">\[
\bar{X} = \frac{1}{N} \sum_{i=1}^N X_i, \,\,\,\,
s =  \sqrt{\frac{1}{N-1} \sum_{i=1}^N (X_i - \bar{X})^2}
\]</span></p>
<p>You can see that this is the case by typing:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="kw">length</span>(x)
s<span class="op">-</span><span class="kw">sd</span>(x)<span class="op">*</span><span class="kw">sqrt</span>((n<span class="op">-</span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>n)
<span class="co">#&gt; [1] 0</span></code></pre></div>
<p>For all the theory discussed here, you need to compute the actual standard deviation as defined:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sqrt</span>(<span class="kw">mean</span>((x<span class="op">-</span>m)<span class="op">^</span><span class="dv">2</span>))</code></pre></div>
<p>So be careful when using the <code>sd</code> function in R. However, keep in mind that throughout the book we sometimes use the <code>sd</code> function when we really want the actual SD. This is because when the list size is big, these two are practically equivalent since <span class="math inline">\(\sqrt{(N-1)/N} \approx 1\)</span>.</p>
</div>
</div>
<div id="central-limit-theorem" class="section level2">
<h2><span class="header-section-number">14.7</span> Central Limit Theorem</h2>
<p>The Central Limit Theorem (CLT) tells us that when the number of draws, also called the <em>sample size</em>, is large, the probability distribution of the sum of the independent draws is approximately normal. Because sampling models are used for so many data generation processes, the CLT is considered one of the most important mathematical insights in history.</p>
<p>Previously, we discussed that if we know that the distribution of a list of numbers is approximated by the normal distribution, all we need to describe the list are the average and standard deviation. We also know that the same applies to probability distributions. If a random variable has a probability distribution that is approximated with the normal distribution, then all we need to describe the probability distribution are the average and standard deviation, referred to as the expected value and standard error.</p>
<p>We previously ran this Monte Carlo simulation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">1000</span>
B &lt;-<span class="st"> </span><span class="dv">10000</span>
roulette_winnings &lt;-<span class="st"> </span><span class="cf">function</span>(n){
  X &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), n, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">9</span><span class="op">/</span><span class="dv">19</span>, <span class="dv">10</span><span class="op">/</span><span class="dv">19</span>))
  <span class="kw">sum</span>(X)
}
S &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, <span class="kw">roulette_winnings</span>(n))</code></pre></div>
<p>The Central Limit Theorem (CLT) tells us that the sum <span class="math inline">\(S\)</span> is approximated by a normal distribution. Using the formulas above, we know that the expected value and standard error are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n <span class="op">*</span><span class="st"> </span>(<span class="dv">20</span><span class="op">-</span><span class="dv">18</span>)<span class="op">/</span><span class="dv">38</span> 
<span class="co">#&gt; [1] 52.6</span>
<span class="kw">sqrt</span>(n) <span class="op">*</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">90</span>)<span class="op">/</span><span class="dv">19</span> 
<span class="co">#&gt; [1] 31.6</span></code></pre></div>
<p>The theoretical values above match those obtained with the Monte Carlo simulation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(S)
<span class="co">#&gt; [1] 52.2</span>
<span class="kw">sd</span>(S)
<span class="co">#&gt; [1] 31.7</span></code></pre></div>
<p>Using the CLT, we can skip the Monte Carlo simulation and instead compute the probability of the casino losing money using this approximation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu &lt;-<span class="st"> </span>n <span class="op">*</span><span class="st"> </span>(<span class="dv">20</span><span class="op">-</span><span class="dv">18</span>)<span class="op">/</span><span class="dv">38</span>
se &lt;-<span class="st">  </span><span class="kw">sqrt</span>(n) <span class="op">*</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">90</span>)<span class="op">/</span><span class="dv">19</span> 
<span class="kw">pnorm</span>(<span class="dv">0</span>, mu, se)
<span class="co">#&gt; [1] 0.0478</span></code></pre></div>
<p>which is also in very good agreement with our Monte Carlo result:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(S <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>)
<span class="co">#&gt; [1] 0.0458</span></code></pre></div>
<div id="how-large-is-large-in-the-central-limit-theorem" class="section level3">
<h3><span class="header-section-number">14.7.1</span> How large is large in the Central Limit Theorem?</h3>
<p>The CLT works when the number of draws is large. But large is a relative term. In many circumstances as few as 30 draws is enough to make the CLT useful. In some specific instances, as few as 10 is enough. However, these should not be considered general rules. Note, for example, that when the probability of success is very small, we need much larger sample sizes.</p>
<p>By way of illustration, let’s consider the lottery. In the lottery, the chances of winning are less than 1 in a million. Thousands of people play so the number of draws is very large. Yet the number of winners, the sum of the draws, range between 0 and 4. This sum is certainly not well approximated by a normal distribution, so the CLT does not apply, even with the very large sample size. This is generally true when the probability of a success is very low. In these cases, the Poisson distribution is more appropriate.</p>
<p>You can examine the properties of the Poisson distribution using <code>dpois</code> and <code>ppois</code>. You can generate random variables following this distribution with <code>rpois</code>. However, we do not cover the theory here. You can learn about the Poisson distribution in any probability textbook and even Wikipedia<a href="#fn49" class="footnoteRef" id="fnref49"><sup>49</sup></a></p>
</div>
</div>
<div id="statistical-properties-of-averages" class="section level2">
<h2><span class="header-section-number">14.8</span> Statistical properties of averages</h2>
<p>There are several useful mathematical results that we used above and often employ when working with data. We list them below.</p>
<p>1. The expected value of the sum of random variables is the sum of each random variable’s expected value. We can write it like this:</p>
<p><span class="math display">\[ 
\mbox{E}[X_1+X_2+\dots+X_n] =  \mbox{E}[X_1] + \mbox{E}[X_2]+\dots+\mbox{E}[X_n]
\]</span></p>
<p>If the <span class="math inline">\(X\)</span> are independent draws from the urn, then they all have the same expected value. Let’s call it <span class="math inline">\(\mu\)</span> and thus:</p>
<p><span class="math display">\[ 
\mbox{E}[X_1+X_2+\dots+X_n]=  n\mu
\]</span></p>
<p>which is another way of writing the result we show above for the sum of draws.</p>
<p>2. The expected value of a non-random constant times a random variable is the non-random constant times the expected value of a random variable. This is easier to explain with symbols:</p>
<p><span class="math display">\[
\mbox{E}[aX] =  a\times\mbox{E}[X]
\]</span></p>
<p>To see why this is intuitive, consider change of units. If we change the units of a random variable, say from dollars to cents, the expectation should change in the same way. A consequence of the above two facts is that the expected value of the average of independent draws from the same urn is the expected value of the urn, call it <span class="math inline">\(\mu\)</span> again:</p>
<p><span class="math display">\[
\mbox{E}[(X_1+X_2+\dots+X_n) / n]=   \mbox{E}[X_1+X_2+\dots+X_n] / n = n\mu/n = \mu 
\]</span></p>
<p>3. The square of the standard error of the sum of <strong>independent</strong> random variables is the sum of the square of the standard error of each random variable. This one is easier to understand in math form:</p>
<p><span class="math display">\[ 
\mbox{SE}[X_1+X_2+\dots+X_n] = \sqrt{\mbox{SE}[X_1]^2 + \mbox{SE}[X_2]^2+\dots+\mbox{SE}[X_n]^2  }
\]</span></p>
<p>The square of the standard error is referred to as the <em>variance</em> in statistical textbooks. Note that this particular property is not as intuitive as the previous three and more in depth explanations can be found in statistics textbooks.</p>
<p>4. The standard error of a non-random constant times a random variable is the non-random constant times the random variable’s standard error. As with the expectation: <span class="math display">\[
\mbox{SE}[aX] =  a \times \mbox{SE}[X]
\]</span></p>
<p>To see why this is intuitive, again think of units.</p>
<p>A consequence of 3 and 4 is that the standard error of the average of independent draws from the same urn is the standard deviation of the urn divided by the square root of <span class="math inline">\(n\)</span> (the number of draws), call it <span class="math inline">\(\sigma\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\mbox{SE}[(X_1+X_2+\dots+X_n) / n] &amp;=   \mbox{SE}[X_1+X_2+\dots+X_n]/n \\
&amp;= \sqrt{\mbox{SE}[X_1]^2+\mbox{SE}[X_2]^2+\dots+\mbox{SE}[X_n]^2}/n \\
&amp;= \sqrt{\sigma^2+\sigma^2+\dots+\sigma^2}/n\\
&amp;= \sqrt{n\sigma^2}/n\\
&amp;= \sigma / \sqrt{n}    
\end{aligned}
\]</span></p>
<p>5. If <span class="math inline">\(X\)</span> is a normally distributed random variable, then if <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are non-random constants, <span class="math inline">\(aX + b\)</span> is also a normally distributed random variable. All we are doing is changing the units of the random variable by multiplying by <span class="math inline">\(a\)</span>, then shifting the center by <span class="math inline">\(b\)</span>.</p>
<p>Note that statistical textbooks use the Greek letters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> to denote the expected value and standard error, respectively. This is because <span class="math inline">\(\mu\)</span> is the Greek letter for <span class="math inline">\(m\)</span>, the first letter of <em>mean</em>, which is another term used for expected value. Similarly, <span class="math inline">\(\sigma\)</span> is the Greek letter for <span class="math inline">\(s\)</span>, the first letter of standard error.</p>
</div>
<div id="law-of-large-numbers" class="section level2">
<h2><span class="header-section-number">14.9</span> Law of large numbers</h2>
<p>An important implication of the final result is that the standard error of the average becomes smaller and smaller as <span class="math inline">\(n\)</span> grows larger. When <span class="math inline">\(n\)</span> is very large, then the standard error is practically 0 and the average of the draws converges to the average of the urn. This is known in statistical textbooks as the law of large numbers or the law of averages.</p>
<div id="misinterpreting-law-of-averages" class="section level3">
<h3><span class="header-section-number">14.9.1</span> Misinterpreting law of averages</h3>
<p>The law of averages is sometimes misinterpreted. For example, if you toss a coin 5 times and see a head each time, you might hear someone argue that the next toss is probably a tail because of the law of averages: on average we should see 50% heads and 50% tails. A similar argument would be to say that red “is due” on the roulette wheel after seeing black come up five times in a row. These events are independent so the chance of a coin landing heads is 50% regardless of the previous 5. This is also the case for the roulette outcome. The law of averages applies only when the number of draws is very large and not in small samples. After a million tosses, you will definitely see about 50% heads regardless of the outcome of the first five tosses.</p>
<p>Another funny misuse of the law of averages is in sports when TV sportscasters predict a player is about to succeed because they have failed a few times in a row.</p>
</div>
</div>
<div id="exercises-24" class="section level2">
<h2><span class="header-section-number">14.10</span> Exercises</h2>
<p>1. In American Roulette you can also bet on green. There are 18 reds, 18 blacks and 2 greens (0 and 00). What are the chances the green comes out?</p>
<p>2. The payout for winning on green is $17 dollars. This means that if you bet a dollar and it lands on green, you get $17. Create a sampling model using sample to simulate the random variable <span class="math inline">\(X\)</span> for your winnings. Hint: see the example below for how it should look like when betting on red.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>), <span class="dv">1</span>, <span class="dt">prob =</span> <span class="kw">c</span>(<span class="dv">9</span><span class="op">/</span><span class="dv">19</span>, <span class="dv">10</span><span class="op">/</span><span class="dv">19</span>))</code></pre></div>
<p>3. Compute the expected value of <span class="math inline">\(X\)</span>.</p>
<p>4. Compute the standard error of <span class="math inline">\(X\)</span>.</p>
<p>5. Now create a random variable <span class="math inline">\(S\)</span> that is the sum of your winnings after betting on green 1000 times. Hint: change the argument <code>size</code> and <code>replace</code> in your answer to question 2. Start your code by setting the seed to 1 with <code>set.seed(1)</code>.</p>
<p>6. What is the expected value of <span class="math inline">\(S\)</span>?</p>
<p>7. What is the standard error of <span class="math inline">\(S\)</span>?</p>
<p>8. What is the probability that you end up winning money? Hint: use the CLT.</p>
<p>9. Create a Monte Carlo simulation that generates 1,000 outcomes of <span class="math inline">\(S\)</span>. Compute the average and standard deviation of the resulting list to confirm the results of 6 and 7. Start your code by setting the seed to 1 with <code>set.seed(1)</code>.</p>
<p>10. Now check your answer to 8 using the Monte Carlo result.</p>
<p>11. The Monte Carlo result and the CLT approximation are close, but not that close. What could account for this?</p>
<ol style="list-style-type: lower-alpha">
<li>1,000 simulations is not enough. If we do more, they match.</li>
<li>The CLT does not work as well when the probability of success is small. In this case, it was 1/19. If we make the number of roulette plays bigger, they will match better.</li>
<li>The difference is within rounding error.</li>
<li>The CLT only works for averages.</li>
</ol>
<p>12. Now create a random variable <span class="math inline">\(Y\)</span> that is your average winnings per bet after playing off your winnings after betting on green 1,000 times.</p>
<p>13. What is the expected value of <span class="math inline">\(Y\)</span>?</p>
<p>14. What is the standard error of <span class="math inline">\(Y\)</span>?</p>
<p>15. What is the probability that you end up with winnings per game that are positive? Hint: use the CLT.</p>
<p>16. Create a Monte Carlo simulation that generates 2,500 outcomes of <span class="math inline">\(Y\)</span>. Compute the average and standard deviation of the resulting list to confirm the results of 6 and 7. Start your code by setting the seed to 1 with <code>set.seed(1)</code>.</p>
<p>17. Now check your answer to 8 using the Monte Carlo result.</p>
<p>18. The Monte Carlo result and the CLT approximation are now much closer. What could account for this?</p>
<ol style="list-style-type: lower-alpha">
<li>We are now computing averages instead of sums.</li>
<li>2,500 Monte Carlo simulations is not better than 1,000.</li>
<li>The CLT works better when the sample size is larger. We increased from 1,000 to 2,500.</li>
<li>It is not closer. The difference is within rounding error.</li>
</ol>

</div>
<div id="case-study-the-big-short" class="section level2">
<h2><span class="header-section-number">14.11</span> Case study: The Big Short</h2>
<div id="interest-rates-explained-with-chance-model" class="section level3">
<h3><span class="header-section-number">14.11.1</span> Interest rates explained with chance model</h3>
<p>More complex versions of the sampling models we have discussed are also used by banks to decide interest rates. Suppose you run a small bank that has a history of identifying potential homeowners that can be trusted to make payments. In fact, historically, in a given year, only 2% of your customers default, meaning that they don’t pay back the money that you lent them. However, you are aware that if you simply loan money to everybody without interest, you will end up losing money due to this 2%. Although you know 2% of your clients will probably default, you don’t know which ones. Yet by charging everybody just a bit extra in interest, you can make up the losses incurred due to that 2% and also cover your operating costs. You can also make a profit, but if you set the interest rates too high, your clients will go to another bank. We use all these facts and some probability theory to decide what interest rate you should charge.</p>
<p>Suppose your bank will give out 1,000 loans for $180,000 this year. Also, after adding up all costs, suppose your bank loses $200,000 per foreclosure. For simplicity, we assume this includes all operational costs. A sampling model for this scenario can be coded like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">1000</span>
loss_per_foreclosure &lt;-<span class="st"> </span><span class="op">-</span><span class="dv">200000</span>
p &lt;-<span class="st"> </span><span class="fl">0.02</span> 
defaults &lt;-<span class="st"> </span><span class="kw">sample</span>( <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), n, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">-</span>p, p), <span class="dt">replace =</span> <span class="ot">TRUE</span>)
<span class="kw">sum</span>(defaults <span class="op">*</span><span class="st"> </span>loss_per_foreclosure)
<span class="co">#&gt; [1] -5400000</span></code></pre></div>
<p>Note that the total loss defined by the final sum is a random variable. Every time you run the above code, you get a different answer. We can easily construct a Monte Carlo simulation to get an idea of the distribution of this random variable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">B &lt;-<span class="st"> </span><span class="dv">10000</span>
losses &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, {
    defaults &lt;-<span class="st"> </span><span class="kw">sample</span>( <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), n, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">-</span>p, p), <span class="dt">replace =</span> <span class="ot">TRUE</span>) 
  <span class="kw">sum</span>(defaults <span class="op">*</span><span class="st"> </span>loss_per_foreclosure)
})</code></pre></div>
<!--
Here is the distribution of this random variable:
<img src="book_files/figure-html/losses-distribution-1.png" width="70%" style="display: block; margin: auto;" />
-->
<p>We don’t really need a Monte Carlo simulation though. Using what we have learned, the CLT tells us that because our losses are a sum of independent draws, its distribution is approximately normal with expected value and standard errors given by:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n<span class="op">*</span>(p<span class="op">*</span>loss_per_foreclosure <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>p)<span class="op">*</span><span class="dv">0</span>)
<span class="co">#&gt; [1] -4e+06</span>
<span class="kw">sqrt</span>(n)<span class="op">*</span><span class="kw">abs</span>(loss_per_foreclosure)<span class="op">*</span><span class="kw">sqrt</span>(p<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p))
<span class="co">#&gt; [1] 885438</span></code></pre></div>
<p>We can now set an interest rate to guarantee that, on average, we break even. Basically, we need to add a quantity <span class="math inline">\(x\)</span> to each loan, which in this case are represented by draws, so that the expected value is 0. If we define <span class="math inline">\(l\)</span> to be the loss per foreclosure, we need:</p>
<p><span class="math display">\[
lp  + x(1-p) = 0
\]</span></p>
<p>which implies <span class="math inline">\(x\)</span> is</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="op">-</span><span class="st"> </span>loss_per_foreclosure<span class="op">*</span>p<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>p)
<span class="co">#&gt; [1] 4082</span></code></pre></div>
<p>or an interest rate of 0.023.</p>
<p>However, we still have a problem. Although this interest rate guarantees that on average we break even, there is a 50% chance that we lose money. If our bank loses money, we have to close it down. We therefore need to pick an interest rate that makes it unlikely for this to happen. At the same time, if the interest rate is too high, our clients will go to another bank so we must be willing to take some risks. So let’s say that we want our chances of losing money to be 1 in 100, what does the <span class="math inline">\(x\)</span> quantity need to be now? This one is a bit harder. We want the sum <span class="math inline">\(S\)</span> to have:</p>
<p><span class="math display">\[\mbox{Pr}(S&lt;0) = 0.01\]</span></p>
<p>We know that <span class="math inline">\(S\)</span> is approximately normal. The expected value of <span class="math inline">\(S\)</span> is</p>
<p><span class="math display">\[\mbox{E}[S] = \{ lp + x(1-p)\}n\]</span></p>
<p>with <span class="math inline">\(n\)</span> the number of draws, which in this case represents loans. The standard error is</p>
<p><span class="math display">\[\mbox{SD}[S] = |x-l| \sqrt{np(1-p)}.\]</span></p>
<p>Because <span class="math inline">\(x\)</span> is positive and <span class="math inline">\(l\)</span> negative <span class="math inline">\(|x-l|=x-l\)</span>. Note that these are just an application of the formulas shown earlier, but using more compact symbols.</p>
<p>Now we are going to use a mathematical “trick” that is very common in statistics. We add and subtract the same quantities to both sides of the event <span class="math inline">\(S&lt;0\)</span> so that the probability does not change and we end up with a standard normal random variable on the left, which will then permit us to write down an equation with only <span class="math inline">\(x\)</span> as an unknown. This “trick” is as follows:</p>
<p>If <span class="math inline">\(\mbox{Pr}(S&lt;0) = 0.01\)</span> then <span class="math display">\[
\mbox{Pr}\left(\frac{S - \mbox{E}[S]}{\mbox{SE}[S]} &lt; \frac{ - \mbox{E}[S]}{\mbox{SE}[S]}\right)
\]</span> And remember <span class="math inline">\(\mbox{E}[S]\)</span> and <span class="math inline">\(\mbox{SE}[S]\)</span> are the expected value and standard error of <span class="math inline">\(S\)</span>, respectively. All we did above was add and divide by the same quantity on both sides. We did this because now the term on the left is a standard normal random variable, which we will rename <span class="math inline">\(Z\)</span>. Now we fill in the blanks with the actual formula for expected value and standard error:</p>
<p><span class="math display">\[
\mbox{Pr}\left(Z &lt;  \frac{- \{ lp + x(1-p)\}n}{(x-l) \sqrt{np(1-p)}}\right) = 0.01
\]</span></p>
<p>It may look complicated, but remember that <span class="math inline">\(l\)</span>, <span class="math inline">\(p\)</span> and <span class="math inline">\(n\)</span> are all known amounts, so eventually we will replace them with numbers.</p>
<p>Now because the Z is a normal random with expected value 0 and standard error 1, it means that the quantity on the right side of the &lt; sign must be equal to:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qnorm</span>(<span class="fl">0.01</span>)
<span class="co">#&gt; [1] -2.33</span></code></pre></div>
<p>for the equation to hold true. Remember that <span class="math inline">\(z=\)</span><code>qnorm(0.01)</code> gives us the value of <span class="math inline">\(z\)</span> for which:</p>
<p><span class="math display">\[
\mbox{Pr}(Z \leq z) = 0.01
\]</span></p>
<p>So this means that the right side of the complicated equation must be <span class="math inline">\(z\)</span>=<code>qnorm(0.01)</code>.</p>
<p><span class="math display">\[
\frac{- \{ lp + x(1-p)\}n} {(x-l) \sqrt{n p (1-p)}} = z
\]</span></p>
<p>The trick works because we end up with an expression containing <span class="math inline">\(x\)</span> that we know has to be equal to a known quantity <span class="math inline">\(z\)</span>. Solving for <span class="math inline">\(x\)</span> is now simply algebra:</p>
<p><span class="math display">\[ x = - l \frac{ np  - z \sqrt{np(1-p)}}{n(1-p) + z \sqrt{np(1-p)}}\]</span></p>
<p>which is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">l &lt;-<span class="st"> </span>loss_per_foreclosure
z &lt;-<span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.01</span>)
x &lt;-<span class="st"> </span><span class="op">-</span>l<span class="op">*</span>( n<span class="op">*</span>p <span class="op">-</span><span class="st"> </span>z<span class="op">*</span><span class="kw">sqrt</span>(n<span class="op">*</span>p<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p)))<span class="op">/</span><span class="st"> </span>( n<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p) <span class="op">+</span><span class="st"> </span>z<span class="op">*</span><span class="kw">sqrt</span>(n<span class="op">*</span>p<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p)))
x
<span class="co">#&gt; [1] 6249</span></code></pre></div>
<p>Our interest rate now goes up to 0.035. This is still a very competitive interest rate. By choosing this interest rate, we now have an expected profit per loan of:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">loss_per_foreclosure<span class="op">*</span>p <span class="op">+</span><span class="st"> </span>x<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p)
<span class="co">#&gt; [1] 2124</span></code></pre></div>
<p>which is a total expected profit of about:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n<span class="op">*</span>(loss_per_foreclosure<span class="op">*</span>p <span class="op">+</span><span class="st"> </span>x<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p)) 
<span class="co">#&gt; [1] 2124198</span></code></pre></div>
<p>dollars!</p>
<p>We can run a Monte Carlo simulation to double check our theoretical approximations:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">B &lt;-<span class="st"> </span><span class="dv">100000</span>
profit &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, {
    draws &lt;-<span class="st"> </span><span class="kw">sample</span>( <span class="kw">c</span>(x, loss_per_foreclosure), n, 
                        <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">-</span>p, p), <span class="dt">replace =</span> <span class="ot">TRUE</span>) 
    <span class="kw">sum</span>(draws)
})
<span class="kw">mean</span>(profit)
<span class="co">#&gt; [1] 2119582</span>
<span class="kw">mean</span>(profit<span class="op">&lt;</span><span class="dv">0</span>)
<span class="co">#&gt; [1] 0.0124</span></code></pre></div>
</div>
<div id="the-big-short" class="section level3">
<h3><span class="header-section-number">14.11.2</span> The Big Short</h3>
<p>One of your employees points out that since the bank is making 2,124 dollars per loan, the bank should give out more loans! Why just <span class="math inline">\(n\)</span>? You explain that finding those <span class="math inline">\(n\)</span> clients was hard. You need a group that is predictable and that keeps the chances of defaults low. He then points out that even if the probability of default is higher, as long as our expected value is positive, you can minimize your chances of losses by increasing <span class="math inline">\(n\)</span> and relying on the law of large numbers.</p>
<p>He claims that even if the default rate is twice as high, say 4%, if we set the rate just a bit higher than this value:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p &lt;-<span class="st"> </span><span class="fl">0.04</span>
r &lt;-<span class="st"> </span>(<span class="op">-</span><span class="st"> </span>loss_per_foreclosure<span class="op">*</span>p<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>p)) <span class="op">/</span><span class="st"> </span><span class="dv">180000</span>
r
<span class="co">#&gt; [1] 0.0463</span></code></pre></div>
<p>we will profit. At 5%, we are guaranteed a positive expected value of:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r &lt;-<span class="st"> </span><span class="fl">0.05</span>
x &lt;-<span class="st"> </span>r<span class="op">*</span><span class="dv">180000</span>
loss_per_foreclosure<span class="op">*</span>p <span class="op">+</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>p)
<span class="co">#&gt; [1] 640</span></code></pre></div>
<p>and can minimize our chances of losing money by simply increasing <span class="math inline">\(n\)</span> since:</p>
<p><span class="math display">\[
\mbox{Pr}(S &lt; 0) = 
\mbox{Pr}\left(Z &lt; - \frac{\mbox{E}[S]}{\mbox{SE}[S]}\right)
\]</span> with <span class="math inline">\(Z\)</span> a standard normal random variable as shown earlier. If we define <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> to be the expected value and standard deviation of the urn, respectively (that is of a single loan), using the formulas above we have: <span class="math inline">\(\mbox{E}[S]= n\mu\)</span> and <span class="math inline">\(\mbox{SE}[S]= \sqrt{n}\sigma\)</span>. So if we define <span class="math inline">\(z\)</span>=<code>qnorm(0.01)</code>, we have: <span class="math display">\[
 - \frac{n\mu}{\sqrt{n}\sigma} = - \frac{\sqrt{n}\mu}{\sigma} = z
\]</span> which implies that if we let:</p>
<p><span class="math display">\[
n \geq z^2 \sigma^2 / \mu^2
\]</span> we are guaranteed to have a probability of less than 0.01. The implication is that, as long as <span class="math inline">\(\mu\)</span> is positive, we can find an <span class="math inline">\(n\)</span> that minimizes the probability of a loss. This is a form of the law of large numbers: when <span class="math inline">\(n\)</span> is large, our average earnings per loan converges to the expected earning <span class="math inline">\(\mu\)</span>.</p>
<p>With <span class="math inline">\(x\)</span> fixed, now we can ask what <span class="math inline">\(n\)</span> do we need for the probability to be 0.01? In our example, if we give out:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">z &lt;-<span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.01</span>)
n &lt;-<span class="st"> </span><span class="kw">ceiling</span>((z<span class="op">^</span><span class="dv">2</span><span class="op">*</span>(x<span class="op">-</span>l)<span class="op">^</span><span class="dv">2</span><span class="op">*</span>p<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p))<span class="op">/</span>(l<span class="op">*</span>p <span class="op">+</span><span class="st"> </span>x<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p))<span class="op">^</span><span class="dv">2</span>)
n
<span class="co">#&gt; [1] 22163</span></code></pre></div>
<p>loans, the probability of losing is about 0.01 and we are expected to earn a total of</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n<span class="op">*</span>(loss_per_foreclosure<span class="op">*</span>p <span class="op">+</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>p))
<span class="co">#&gt; [1] 14184320</span></code></pre></div>
<p>dollars! We can confirm this with a Monte Carlo simulation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p &lt;-<span class="st"> </span><span class="fl">0.04</span>
x &lt;-<span class="st"> </span><span class="fl">0.05</span><span class="op">*</span><span class="dv">180000</span>
profit &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, {
    draws &lt;-<span class="st"> </span><span class="kw">sample</span>( <span class="kw">c</span>(x, loss_per_foreclosure), n, 
                        <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">-</span>p, p), <span class="dt">replace =</span> <span class="ot">TRUE</span>) 
    <span class="kw">sum</span>(draws)
})
<span class="kw">mean</span>(profit)
<span class="co">#&gt; [1] 14160716</span></code></pre></div>
<p>This seems like a no brainer. As a result, your colleague decides to leave your bank and start his own high-risk mortgage company. A few months later, your colleague’s bank has gone bankrupt. A book is written and eventually a movie is made relating the mistake your friend, and many others, made. What happened?</p>
<p>Your colleague’s scheme was mainly based on this mathematical formula: <span class="math display">\[
    \mbox{SE}[(X_1+X_2+\dots+X_n) / n] = \sigma / \sqrt{n}    
\]</span></p>
<p>By making <span class="math inline">\(n\)</span> large, we minimize the standard error of our per-loan profit. However, for this rule to hold, the <span class="math inline">\(X\)</span>s must be independent draws: one person defaulting must be independent of others defaulting. Note that in the case of averaging the <strong>same</strong> event over and over, an extreme example of events that are not independent, we get a standard error that is <span class="math inline">\(\sqrt{n}\)</span> times bigger: <span class="math display">\[
    \mbox{SE}[(X_1+X_1+\dots+X_1) / n] =  \mbox{SE}[n X_1  / n] = \sigma &gt; \sigma / \sqrt{n} 
\]</span></p>
<p>To construct a more realistic simulation than the original one your colleague ran, let’s assume there is a global event that affects everybody with high-risk mortgages and changes their probability. We will assume that with 50-50 chance, all the probabilities go up or down slightly to somewhere between 0.03 and 0.05. But it happens to everybody at once, not just one person. These draws are no longer independent.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p &lt;-<span class="st"> </span><span class="fl">0.04</span>
x &lt;-<span class="st"> </span><span class="fl">0.05</span><span class="op">*</span><span class="dv">180000</span>
profit &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, {
    new_p &lt;-<span class="st"> </span><span class="fl">0.04</span> <span class="op">+</span><span class="st"> </span><span class="kw">sample</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="fl">0.01</span>, <span class="fl">0.01</span>, <span class="dt">length =</span> <span class="dv">100</span>), <span class="dv">1</span>)
    draws &lt;-<span class="st"> </span><span class="kw">sample</span>( <span class="kw">c</span>(x, loss_per_foreclosure), n, 
                        <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">-</span>new_p, new_p), <span class="dt">replace =</span> <span class="ot">TRUE</span>) 
    <span class="kw">sum</span>(draws)
})</code></pre></div>
<p>Note that our expected profit is still large:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(profit)
<span class="co">#&gt; [1] 14103909</span></code></pre></div>
<p>However, the probability of the bank having negative earnings shoots up to:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(profit<span class="op">&lt;</span><span class="dv">0</span>)
<span class="co">#&gt; [1] 0.349</span></code></pre></div>
<p>Even scarier is that the probability of losing more than 10 million dollars is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(profit <span class="op">&lt;</span><span class="st"> </span><span class="op">-</span><span class="dv">10000000</span>)
<span class="co">#&gt; [1] 0.242</span></code></pre></div>
<p>To understand how this happens look at the distribution:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data.frame</span>(<span class="dt">profit_in_millions=</span>profit<span class="op">/</span><span class="dv">10</span><span class="op">^</span><span class="dv">6</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(profit_in_millions)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;black&quot;</span>, <span class="dt">binwidth =</span> <span class="dv">5</span>)</code></pre></div>
<p><img src="book_files/figure-html/profit-distribution-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>The theory completely breaks down and the random variable has much more variability than expected. The financial meltdown of 2007 was due, among other things, to financial “experts” assuming independence when there was none.</p>
</div>
</div>
<div id="exercises-25" class="section level2">
<h2><span class="header-section-number">14.12</span> Exercises</h2>
<p>1. Create a random variable <span class="math inline">\(S\)</span> with the earnings of your bank if you give out 10,000 loans, the default rate is 0.3, and you lose $200,000 in each foreclosure. Hint: use the code we showed in the previous section, but change the parameters.</p>
<p>2. Run a Monte Carlo simulation with 10,000 outcomes for <span class="math inline">\(S\)</span>. Make a histogram of the results.</p>
<p>3. What is the expected value of <span class="math inline">\(S\)</span>?</p>
<p>4. What is the standard error of <span class="math inline">\(S\)</span>?</p>
<p>5. Suppose we give out loans for $180,000. What should the interest rate be so that our expected value is 0?</p>
<p>6. (Harder) What should the interest rate be so that the chance of losing money is 1 in 20? In math notation, what should the interest rate be so that <span class="math inline">\(\mbox{Pr}(S&lt;0) = 0.05\)</span> ?</p>
<p>7. If the bank wants to minimize the probabilities of losing money, which of the following does <strong>not</strong> make interest rates go up?</p>
<ol style="list-style-type: lower-alpha">
<li>A smaller pool of loans.</li>
<li>A larger probability of default.</li>
<li>A smaller required probability of losing money.</li>
<li>The number of Monte Carlo simulations.</li>
</ol>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="46">
<li id="fn46"><p><a href="https://en.wikipedia.org/w/index.php?title=Financial_crisis_of_2007%E2%80%932008">https://en.wikipedia.org/w/index.php?title=Financial_crisis_of_2007%E2%80%932008</a><a href="random-variables.html#fnref46">↩</a></p></li>
<li id="fn47"><p><a href="https://en.wikipedia.org/w/index.php?title=Security_(finance)" class="uri">https://en.wikipedia.org/w/index.php?title=Security_(finance)</a><a href="random-variables.html#fnref47">↩</a></p></li>
<li id="fn48"><p><a href="https://en.wikipedia.org/w/index.php?title=Binomial_distribution" class="uri">https://en.wikipedia.org/w/index.php?title=Binomial_distribution</a><a href="random-variables.html#fnref48">↩</a></p></li>
<li id="fn49"><p><a href="https://en.wikipedia.org/w/index.php?title=Poisson_distribution" class="uri">https://en.wikipedia.org/w/index.php?title=Poisson_distribution</a><a href="random-variables.html#fnref49">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="probability.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="inference.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rafalab/dsbook/edit/master/prob/random-variables-sampling-models-clt.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
